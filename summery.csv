ID,domain,title,abstract,Related (or similar) to the dataset,Venue,Doi,annotated
A1,Autonomous Vehicles,Artificial Intelligence and Internet of Things for Autonomous Vehicles,"Artificial Intelligence (AI) is a machine intelligence tool providing enormous possibilities for smart industrial revolution. Internet of Things (IoT) is the axiom of industry 4.0 revolution, including a worldwide infrastructure for collecting and processing of the data/information from storage, actuation, sensing, advanced services and communication technologies. The combination of high-speed, resilient, low-latency connectivity, and technologies of AI and IoT will enable the transformation towards fully smart Autonomous Vehicle (AV) that illustrate the complementary between real world and digital knowledge for industry 4.0. The purpose of this article is to examine how the latest approaches in AI and IoT can assist in the search for the Autonomous Vehicles. It has been shown that human errors are the source of 90% of automotive crashes, and the safest drivers drive ten times better than the average (Wu et al. Accident Analysis and Prevention, 117, 21–31, 2018). The automated vehicle safety is significant, and users are requiring 1000 times smaller acceptable risk level. Some of the incredible benefits of AVs are: (1) increasing vehicle safety, (2) reduction of accidents, (3) reduction of fuel consumption, (4) releasing of driver time and business opportunities, (5) new potential market opportunities, and (6) reduced emissions and dust particles. However, AVs must use large-scale data/information from their sensors and devices.",,Conference,https://doi.org/10.1007/978-3-030-18963-1_2,Yes
A2,Health,Machine Learning-Based Aggression Detection in Children with ADHD Using Sensor-Based Physical Activity Monitoring,"Aggression in children is highly prevalent and can have devastating consequences, yet there is currently no objective method to track its frequency in daily life. This study aims to investigate the use of wearable-sensor-derived physical activity data and machine learning to objectively identify physical-aggressive incidents in children. Participants (n = 39) aged 7 to 16 years, with and without ADHD, wore a waist-worn activity monitor (ActiGraph, GT3X+) for up to one week, three times over 12 months, while demographic, anthropometric, and clinical data were collected. Machine learning techniques, specifically random forest, were used to analyze patterns that identify physical-aggressive incident with 1-min time resolution. A total of 119 aggression episodes, lasting 7.3 ± 13.1 min for a total of 872 1-min epochs including 132 physical aggression epochs, were collected. The model achieved high precision (80.2%), accuracy (82.0%), recall (85.0%), F1 score (82.4%), and area under the curve (89.3%) to distinguish physical aggression epochs. The sensor-derived feature of vector magnitude (faster triaxial acceleration) was the second contributing feature in the model, and significantly distinguished aggression and non-aggression epochs. If validated in larger samples, this model could provide a practical and efficient solution for remotely detecting and managing aggressive incidents in children.",,Q2 journal,https://doi.org/10.3390/s23104949,Yes
A3,NLP,A Streaming Machine Learning Framework for Online Aggression Detection on Twitter,"The rise of online aggression on social media is evolving into a major point of concern. Several machine and deep learning approaches have been proposed recently for detecting various types of aggressive behavior. However, social media are fast-paced, generating an increasing amount of content, while aggressive behavior evolves over time. In this work, we introduce the first, practical, real-time framework for detecting aggression on Twitter via embracing the streaming machine learning paradigm. Our method adapts its ML classifiers in an incremental fashion as it receives new annotated examples and is able to achieve the same (or even higher) performance as batch-based ML models, with over 90% accuracy, precision, and recall. At the same time, our experimental analysis on real Twitter data reveals how our framework can easily scale to accommodate the entire Twitter Firehose (of 778 million tweets per day) with only 3 commodity machines. Finally, we show that our framework is general enough to detect other related behaviors such as sarcasm, racism, and sexism in real time.",,Conference,10.1109/BigData50022.2020.9377980,Yes
A4,Autonomous Vehicles,APPLICATION OF DRONES WITH ARTIFICIAL INTELLIGENCE FOR MILITARY PURPOSES,"One does not have to look far to see how Artificial Intelligence (AI) - the ability of machines to perform tasks that typically require human intelligence - is transforming the international security environment in which all involved security forces operate. Due to its cross-cutting nature, AI will pose a broad set of international security challenges, affecting both traditional military capabilities and the realm of hybrid threats, and will likewise provide new opportunities to respond to them. AI will have an impact on all of the core tasks of every collective defense, crisis management, and cooperative security system. With new opportunities, risks, and threats to prosperity and security at stake, the promise and peril associated with this foundational technology are too vast for any single actor to manage alone. As a result, cooperation is inherently needed to equally mitigate international security risks, as well as to capitalize on the technology’s potential to transform enterprise functions, mission support, and operations.",,Conference,http://www.vti.mod.gov.rs/oteh22/elementi/rad/075.pdf,Yes
A5,Autonomous Vehicles,"Case studies on the usability, acceptability and functionality of autonomous mobile delivery robots in real-world healthcare settings","Autonomous mobile delivery robots are used as a way to improve efficiency in hospitals and reduce staff workload amongst a growing workforce shortage in healthcare. These two case studies investigated the usability, acceptability and functionality of two GoCart delivery robots at two different healthcare settings. The GoCart robots assisted with delivering blood and urine samples at a pathology laboratory and delivering meals at a residential care facility during a two-week period. A total of 50 participants (direct and secondary users, and managers) were interviewed about their experiences with the robot and answered questions about its design and functionality, safety and security, usability and their overall attitudes towards having the robot at their facility. Results showed that the participants from both sites thought the robots could be a good addition to their facilities to improve efficiency and reduce staff workload. The robot was received more positively at the residential care facility than the pathology laboratory. Improvements still need to be made to adapt the robots to each site before implementing the GoCarts long term, including changes to the size and screen. These case studies demonstrate that autonomous mobile delivery robots could be a useful addition to residential care facilities and pathology laboratory sites. Overall, this research adds to the current evidence showing potential uses for delivery robots and highlights important design considerations.",,Q1 journal,,Yes
A6,Autonomous Vehicles,Forward Collision Avoidance Systems Considering Driver's Driving Behavior Recognized by Gaussian Mixture Model,"Although it is well known that driver's intention and driving behavior have great influence on the performance of the advanced driver assistance systems (ADAS), little consideration has been taken in the design of the existing systems. To improve the system performance, in particular, the acceptance and adaption of ADAS to human drivers, it is important to understand human drivers' intention and driving behavior that makes the systems more human-like or personalized for forward collision avoidance (FCA) and autonomous emergency braking (AEB). The research presented in this paper proposed a method to recognize driver's intention and driving behavior based on Gaussian Mixture Model (GMM). A typical testing scenarios of longitudinal braking case was created under a real-time driving simulator with both PanoSim-RT® and dSPACE®. The samples with 36 drivers were used for the testing, and the driving data were collected, analyzed and further employed in driving behavior recognition via a Gaussian mixture model. An optimization method was taken in model parameter identification. The parameters were used in the control design of FCA systems. Compared with existing FCA systems, the proposed personalized systems have demonstrated advantages in both performance and human acceptance.",,Conference,10.1109/IVS.2017.7995773,Yes
A7,Health,Behavioral Modeling for Mental Health using Machine Learning Algorithms,"Mental health is an indicator of emotional, psychological and social well-being of an individual. It determines how an individual thinks, feels and handle situations. Positive mental health helps one to work productively and realize their full potential. Mental health is important at every stage of life, from childhood and adolescence through adulthood. Many factors contribute to mental health problems which lead to mental illness like stress, social anxiety, depression, obsessive compulsive disorder, drug addiction, and personality disorders. It is becoming increasingly important to determine the onset of the mental illness to maintain proper life balance. The nature of machine learning algorithms and Artificial Intelligence (AI) can be fully harnessed for predicting the onset of mental illness. Such applications when implemented in real time will benefit the society by serving as a monitoring tool for individuals with deviant behavior. This research work proposes to apply various machine learning algorithms such as support vector machines, decision trees, naïve Bayes classifier, K-nearest neighbor classifier and logistic regression to identify state of mental health in a target group. The responses obtained from the target group for the designed questionnaire were first subject to unsupervised learning techniques. The labels obtained as a result of clustering were validated by computing the Mean Opinion Score. These cluster labels were then used to build classifiers to predict the mental health of an individual. Population from various groups like high school students, college students and working professionals were considered as target groups. The research presents an analysis of applying the aforementioned machine learning algorithms on the target groups and also suggests directions for future work.",,Q2 journal,https://doi.org/10.1007/s10916-018-0934-5,Yes
A8,Security,Machine Learning Techniques for Anomaly Detection in Smart Healthcare,"Anomaly detection is a vital research problem among the different domains intrusion detection, fraud detection, device health monitoring, fault data detection, event detection in sensor networks. Anomalies mean an outlier, noise, novelties, exceptions which do not match the expected behavior of the system. Machine learning techniques work well in identifying these abnormal patterns. In this paper, the unsupervised clustering technique K-means, and its variation K-medoids partitioning are applied to detect anomalies. Sensor-embedded wearable devices are allowing smart healthcare services for people even in remote areas. These devices support continuous monitoring of people's health and allow the caregivers to provide better health assistance. Early-stage anomaly detection in such types of smart healthcare practices increases the efficiency of health services. In experimental discussion, K-means, and K-medoids partitioning clustering algorithms are assessed, and their performance is addressed.",,Conference,10.1109/ICIRCA51532.2021.9544795,Yes
A9,Health,Coronary Heart Disease Diagnosis Through Self-Organizing Map and Fuzzy Support Vector Machine with Incremental Updates,"The trade-off between computation time and predictive accuracy is important in the design and implementation of clinical decision support systems. Machine learning techniques with incremental updates have proven their usefulness in analyzing large collections of medical datasets for disease diagnosis. This research aims to develop a predictive method for heart disease diagnosis using machine learning techniques. To this end, the proposed method is developed by unsupervised and supervised learning techniques. In particular, this research relies on Principal Component Analysis (PCA), Self-Organizing Map, Fuzzy Support Vector Machine (Fuzzy SVM), and two imputation techniques for missing value imputation. Furthermore, we apply the incremental PCA and FSVM for incremental learning of the data to reduce the computation time of disease prediction. Our data analysis on two real-world datasets, Cleveland and Statlog, showed that the use of incremental Fuzzy SVM can significantly improve the accuracy of heart disease classification. The experimental results further revealed that the method is effective in reducing the computation time of disease diagnosis in relation to the non-incremental learning technique.",Cleveland heart disease dataset,Q1 journal,https://doi.org/10.1007/s40815-020-00828-7,Yes
A10,Health,A Machine Learning Approach to Predicting Blood Glucose Levels for Diabetes Management,"Patients with diabetes must continually monitor their blood glucose levels and adjust insulin doses, striving to keep blood glucose levels as close to normal as possible. Blood glucose levels that deviate from the normal range can lead to serious short-term and long-term complications. An automatic prediction model that warned people of imminent changes in their blood glucose levels would enable them to take preventive action. In this paper, we describe a solution that uses a generic physiological model of blood glucose dynamics to generate informative features for a Support Vector Regression model that is trained on patient-specific data. The new model outperforms diabetes experts at predicting blood glucose levels and could be used to anticipate almost a quarter of hypoglycemic events 30 minutes in advance. Although the corresponding precision is currently just 42%, most false alarms are in near-hypoglycemic regions, and therefore, patients responding to these hypo-glycemia alerts would not be harmed by intervention.",,Q1 journal,https://cdn.aaai.org/ocs/ws/ws1170/8737-38029-1-PB.pdf,Yes
A11,Security,A Machine Learning-Based Digital Twin for Anti-Counterfeiting Applications With Copy Detection Patterns,"In this paper, we present a new approach to model a printing-imaging channel using a machine learning-based 'digital twin' for copy detection patterns (CDP). The CDP are considered as modern anti-counterfeiting features in multiple applications. Our digital twin is formulated within the information-theoretic framework of TURBO initially developed for high energy physics simulations, using variational approximations of mutual information for both encoder and decoder in the bidirectional exchange of information. This model extends various architectural designs, including paired pix2pix and unpaired CycleGAN, for image-to-image translation. Applicable to any type of printing and imaging devices, the model needs only training data comprising digital templates sent to a printing device and data acquired by an imaging device. The data can be paired, unpaired, or hybrid, ensuring architectural flexibility and scalability for multiple practical setups. We explore the influence of various architectural factors, metrics, and discriminators on the overall system's performance in generating and predicting printed CDP from their digital versions and vice versa. We also performed a comparison with several state-of-the-art methods for image-to-image translation applications. The simulation code and extended results are publicly available at https://gitlab.unige.ch/sip-group/digital-twin.",UniGe,Conference,10.1109/TIFS.2024.3361798,Yes
A12,Urban studies,A Novel Machine-Learning Tool to Identify Community Risk for Firearm Violence: The Firearm Violence Vulnerability Index,"Firearm violence in the United States is a public health crisis, but accessing accurate firearm assault data to inform prevention strategies is a challenge. Vulnerability indices have been used in other fields to better characterize and identify at-risk populations during crises, but no tool currently exists to predict where rates of firearm violence are highest. We sought to develop and validate a novel machine-learning algorithm, the Firearm Violence Vulnerability Index (FVVI), to forecast community risk for shooting incidents, fill data gaps, and enhance prevention efforts. Open-access 2015 to 2022 fatal and nonfatal shooting incident data from Baltimore, Boston, Chicago, Cincinnati, Los Angeles, New York City, Philadelphia, and Rochester were merged on census tract with 30 population characteristics derived from the 2020 American Community Survey. The data set was split into training (80%) and validation (20%) sets; Chicago data were withheld for an unseen test set. XGBoost, a decision tree-based machine-learning algorithm, was used to construct the FVVI model, which predicts shooting incident rates within urban census tracts. A total of 64,909 shooting incidents in 3,962 census tracts were used to build the model; 14,898 shooting incidents in 766 census tracts were in the test set. Historical third grade math scores and having a parent jailed during childhood were population characteristics exhibiting the greatest impact on FVVI's decision making. The model had strong predictive power in the test set, with a goodness of fit (D^2) of 0.77. The Firearm Violence Vulnerability Index accurately predicts firearm violence in urban communities at a granular geographic level based solely on population characteristics. The Firearm Violence Vulnerability Index can fill gaps in currently available firearm violence data while helping to geographically target and identify social or environmental areas of focus for prevention programs. Dissemination of this standardized risk tool could also enhance firearm violence research and resource allocation.",,Q1 journal,10.1097/TA.0000000000003992,Yes
A13,Biochemistry,AI-DrugNet: A Network-Based Deep Learning Model for Drug Repurposing and Combination Therapy in Neurological Disorders,"Discovering effective therapies is difficult for neurological and developmental disorders in that disease progression is often associated with a complex and interactive mechanism. Over the past few decades, few drugs have been identified for treating Alzheimer’s disease (AD), especially for impacting the causes of cell death in AD. Although drug repurposing is gaining more success in developing therapeutic efficacy for complex diseases such as common cancer, the complications behind AD require further study. Here, we developed a novel prediction framework based on deep learning to identify potential repurposed drug therapies for AD, and more importantly, our framework is broadly applicable and may generalize to identifying potential drug combinations in other diseases. Our prediction framework is as follows: we first built a drug-target pair (DTP) network based on multiple drug features and target features, as well as the associations between DTP nodes where drug-target pairs are the DTP nodes and the associations between DTP nodes are represented as the edges in the AD disease network; furthermore, we incorporated the drug-target feature from the DTP network and the relationship information between drug-drug, target-target, drug-target within and outside of drug-target pairs, representing each drug-combination as a quartet to generate corresponding integrated features; finally, we developed an AI-based Drug discovery Network (AI-DrugNet), which exhibits robust predictive performance. The implementation of our network model helps identify potential repurposed and combination drug options that may serve to treat AD and other diseases.",DrugNet,Q1 journal,10.1016/j.csbj.2023.02.004,Yes
A14,Transportation,Analysis and Prediction of New York City Taxi and Uber Demands,"Taxi and Uber are imperative transportation modes in New York City (NYC). This paper investigates the spatiotemporal distribution of pick-ups of medallion taxis (yellow), Street Hail Livery Service taxis (green), and Uber services in NYC, within the five boroughs: Brooklyn, the Bronx, Manhattan, Queens, and Staten Island. Regression models and machine learning algorithms such as XGboost and random forest are used to predict the ridership of taxis and Uber dataset combined in NYC, given a time window of one-hour and locations within zip-code areas. The dataset consists of over 90 million trips within the period April-September 2014, yellow with 86% the most used in the city, followed by green with 9%, and Uber with 5%. In the outer boroughs, the number of pick-ups is 12.9 million (14%), while 77.9 million (86%) were made in Manhattan only. Yellow is the predominant option in Manhattan and Queens, while green is preferred in Brooklyn and Bronx. In Staten Island, the market is shared between the three services. However, Uber presents a highly rising trend of 81% in Manhattan and 145% in outer boroughs during the analysis period. The regression model XGboost performed best because of its exceptional capacity to catch complex feature dependencies. The XGboost model accomplished an estimation of 38.51 for RMSE and 0.97 for R^2. This model could present valuable insights to taxi companies, decision-makers, and city planners in responding to questions, e.g., how to situate taxis where they are required, understand how ridership shifts over time, and the total number of taxis needed to dispatch to meet the demand.",NYC Taxi Trips,Conference,10.22201/icat.24486736e.2023.21.5.2074,Yes
A15,Economics,Analysis of Income on the Basis of Occupation using Data Mining,"Income forecasting is always the idea of knowing how many people us are around. Here we saw how to use machine learning technology to test people's income according to their different lifestyles. The huge gap between wealth and income, especially in the United States, is a serious problem. One of the possible reasons for reducing the growing economic inequality in the world is the possibility of reducing poverty. The rule of worldwide ethical balance ensures maintainable improvement and financial steadiness of the nation. The governments of different countries are doing their best to solve this problem and find the best solutions. The point of this think about is to demonstrate the utilize of machine learning and Data mining strategies to fathom pay uniformity issues. Machine learning is classified as predicting whether a person has an annual income.",US family income,Conference,10.1109/ICBATS54253.2022.9759040,Yes
A16,Pattren recognition,Automated Newborn Cry Diagnostic System Using Machine Learning Approach,"Researchers have found that crying is an acoustic symptom among unhealthy newborns. This study aims to develop a non-invasive newborn cry diagnostic system (NCDS) using information at different levels of the cry audio signal (CAS) of infants. The unhealthy newborn group in our experiment consists of 34 clinical cases. The proposed machine learning (ML) techniques include the extraction of feature sets of Mel frequency cepstral coefficients (MFCC), auditory-inspired amplitude modulation (AAM) features, and a prosody feature set of tilt, intensity, and rhythm features. The training models are probabilistic neural networks and support vector machine algorithms. The feature sets of AAM and MFCC extract low-level patterns, whereas the prosody feature set of tilt, intensity, and rhythm extracts high-level information in an infant CAS. The AAM feature set in the NCDS has never yet been examined. As an innovative aspect of this study, the AAM feature set is included in the NCDS, and this feature set is fused with the feature sets of MFCC and prosody. As another innovation, we reproduce real-world problems by including many pathologies in the unhealthy group. Among the evaluated frameworks proposed, the fusion of all feature sets improves the system performance. The best result is obtained with the fusion of AAM and MFCC with an F-measure of over 80%. The results of this experiment reveal the usefulness of information at different levels within the CASs of newborns, which vary among healthy and unhealthy groups. Moreover, to identify unhealthy newborns, this information can be captured noninvasively by applying ML methods to the NCDS.",Infant Health and Development Program (IHDP),Conference,10.1016/j.bspc.2021.103434,Yes
A17,Health,"Automated Prediction of Apnea and Hypopnea, Using a LAMSTAR Artificial Neural Network","The prediction of individual episodes of apnea and hypopnea in people with obstructive sleep apnea syndrome has not been thoroughly investigated. Accurate prediction of these events could improve clinical management of this prevalent disease. To evaluate the performance of a system developed to predict episodes of obstructive apnea and hypopnea in individuals with obstructive sleep apnea; to determine the most important signals for making accurate and reliable predictions. We employed LArge Memory STorage And Retrieval (LAMSTAR) artificial neural networks to predict apnea and hypopnea. Wavelet transform-based preprocessing was applied to six physiological signals obtained from a set of polysomnography studies and used to train and test the networks. We tested prediction performance during non-REM and REM sleep as a function of data segment duration and prediction lead time. Measurements included average sensitivities, specificities, positive predictive values, and negative predictive values. Prediction performed best during non-REM sleep, using 30-second segments to predict events up to 30 seconds into the future. Most events were correctly predicted up to 60 seconds in the future. Apnea prediction achieved a sensitivity and specificity up to 80.6 ± 5.6 and 72.8 ± 6.6%, respectively. Hypopnea prediction achieved a sensitivity and specificity up to 74.4 ± 5.9 and 68.8 ± 7.0%, respectively. We report, to our knowledge, the first system to predict individual episodes of apnea and hypopnea. The most important signal for apnea prediction was submental electromyography. The most important signals for hypopnea prediction were submental electromyography and heart rate variability. This prediction system may facilitate improved therapies for obstructive sleep apnea.",Apnea,Conference,10.1164/rccm.200907-1146OC,Yes
A18,Health,Classification of Chest Diseases from X-ray Images on the CheXpert Dataset,"This work proposes a method to classify tuberculosis (TB) disease in a chest radiograph using convolutional neural network (CNN) algorithms. The main contribution of this work is to detect and classify TB disease in addition to the other five different diseases. This is achieved by using a transfer learning technique that utilizes a pre-trained CNN network to classify the TB disease. A comprehensive verification using TensorFlow is carried out to train and validate the proposed technique. This work aimed to use different pre-trained models on the CheXpert dataset and compare the area under the curve (AUC) between the CNN models. From the simulations, it was found that it is possible to classify the TB disease in addition to the other five diseases without having a degradation in the accuracy. The results confirm that transfer learning technique is superior to other methods, which exhibits less time for training and validating the datasets, and has good performance. This work achieved excellent performance in classifying three different diseases (atelectasis, edema, and tuberculosis) with AUC of 0.912, 0.945, and 0.954, respectively. Also, this work achieved second-best performance for classifying pleural effusion and consolidation diseases with AUC of 0.928 and 0.917, respectively. The method proposed in this work can be used for classification of diseases in chest radiograph as an early diagnosis tool in a clinical environment.",CheXpert,Q1 journal,https://doi.org/10.1007/978-981-16-0749-3_64,Yes
A19,Finance,Credit Card Default Prediction using Machine Learning Techniques,"Credit risk plays a major role in the banking industry business. Banks' main activities involve granting loan, credit card, investment, mortgage, and others. Credit card has been one of the most booming financial services by banks over the past years. However, with the growing number of credit card users, banks have been facing an escalating credit card default rate. As such data analytics can provide solutions to tackle the current phenomenon and manage credit risks. This paper provides a performance evaluation of credit card default prediction. Thus, logistic regression, rpart decision tree, and random forest are used to test the variable in predicting credit default and random forest proved to have the higher accuracy and area under the curve. This result shows that random forest best describe which factors should be considered with an accuracy of 82% and an Area under Curve of 77% when assessing the credit risk of credit card customers.",credit card default,Conference,10.1109/ICACCAF.2018.8776802,Yes
A20,Social work,The Application of Machine Learning Methods in Drug Consumption Prediction,"Nowadays, drug abuse is a universal phenomenon. It can bring huge damage to the human body and cause irreversible results. It is important to know what can lead to abuse so that it can be prevented. In order to prevent the abuse of drugs, it is necessary to figure out what elements make people abuse drugs and how they relate to the abuse. According to the drug consumption data from the UCI database, Big Five personality traits (NEO-FFI-R), sensation seeking, impulsivity, and demographic information are considered to be relative elements of abuse. However, how they affect drug abuse is not clear, so they cannot predict the probability of a person abusing a drug. Traditional ways to analyze the data, based on scoring, only provide inaccurate predictive values. Machine learning is very popular nowadays because of its strong learning ability, high efficiency, and high accuracy. In this paper, we build models for accurate prediction of drug abuse with personality traits and other information, based on logistic regression, decision tree, and random forest separately. We find that the sensation of respondents and the country they are from are the most important factors for drug abuse. We conclude that drug abuse is not only dependent on a person’s inner being but also affected by the environment they live in.",Drug consumption,Q1 journal,https://doi.org/10.1007/978-981-15-4409-5_45,Yes
A21,Information systems,Bias in Online Freelance Marketplaces: Evidence from TaskRabbit and Fiverr,"Online freelancing marketplaces have grown quickly in recent years. In theory, these sites offer workers the ability to earn money without the obligations and potential social biases associated with traditional employment frameworks. In this paper, we study whether two prominent online freelance marketplaces—TaskRabbit and Fiverr—are impacted by racial and gender bias. From these two platforms, we collect 13,500 worker profiles and gather information about workers’ gender, race, customer reviews, ratings, and positions in search rankings. In both marketplaces, we find evidence of bias: we find that perceived gender and race are significantly correlated with worker evaluations, which could harm the employment opportunities afforded to the workers. We hope that our study fuels more research on the presence and implications of discrimination in online environments.",Online freelance marketplaces,Q2 journal,https://doi.org/10.1145/2998181.2998327,Yes
A22,Information systems,CrowdAdvisor: A Framework for Freelancer Assessment in Online Marketplace,"Hiring is one of the important challenges in the context of online labor marketplace. Unlike traditional hiring, where workers are hired either as a full time employee or as a contractor, hiring from online marketplaces are done for individual jobs of short duration. As these marketplaces are open for anyone, hiring becomes challenging due to the large number of freelancers applying for a posted job. Quite often, clients use ratings of the freelancers while hiring. However, we have observed that ratings are skewed towards higher values and do not provide valuable insights about freelancers' abilities to do a quality work. Therefore, we propose a multidimensional assessment framework which evaluates freelancers on several dimensions. The proposed framework, not only uses the current information about the freelancer, but also utilizes the past jobs he has performed. The framework is evaluated on the data collected from a popular online marketplace. Our analysis, performed on 7254 jobs and 96,271 applicants, shows that the assessment made by the proposed framework outperforms the baseline algorithm.",Online freelance marketplaces,Conference,10.1109/ICSE-SEIP.2017.23,Yes
A23,Information systems,Analyzing the Content Emphasis of Web Search Engines,"Millions of people search the Web each day. As a consequence, the ranking algorithms employed by Web search engines have a profound influence on which pages users visit. Characterizing this influence, and informing users when different engines favor certain sites or points of view, enables more transparent access to the Web's information. We present PAWS, a platform for analyzing differences among Web search engines. PAWS measures content emphasis: the degree to which differences across search engines' rankings correlate with features of the ranked content, including point of view (e.g., positive or negative orientation toward their company's products) and advertisements. We propose an approach for identifying the orientations in search results at scale, through a novel technique that minimizes the expected number of human judgments required. We apply PAWS to news search on Google and Bing, and find no evidence that the engines emphasize results that express positive orientation toward the engine company's products. We do find that the engines emphasize particular news sites, and that they also favor pages containing their company's advertisements, as opposed to competitor advertisements.",Bing US Queries,Conference,https://doi.org/10.1145/2600428.2609515,Yes
A24,Library and information sciences,ArnetMiner: Extraction and Mining of Academic Social Networks,"This paper addresses several key issues in the ArnetMiner system, which aims at extracting and mining academic social networks. Specifically, the system focuses on: 1) Extracting researcher profiles automatically from the Web; 2) Integrating the publication data into the network from existing digital libraries; 3) Modeling the entire academic network; and 4) Providing search services for the academic network. So far, 448,470 researcher profiles have been extracted using a unified tagging approach. We integrate publications from online Web databases and propose a probabilistic framework to deal with the name ambiguity problem. Furthermore, we propose a unified modeling approach to simultaneously model topical aspects of papers, authors, and publication venues. Search services such as expertise search and people association search have been provided based on the modeling results. In this paper, we describe the architecture and main features of the system. We also present the empirical evaluation of the proposed methods.",ArnetMiner Citation Network,Conference,doi.org/10.1145/1401890.1402008,Yes
A25,Information systems,Amazon.com Recommendations: Item-to-Item Collaborative Filtering,"Recommendation algorithms are best known for their use on e-commerce Web sites, where they use input about a customer's interests to generate a list of recommended items. Many applications use only the items that customers purchase and explicitly rate to represent their interests, but they can also use other attributes, including items viewed, demographic data, subject interests, and favorite artists. At Amazon.com, we use recommendation algorithms to personalize the online store for each customer. The store radically changes based on customer interests, showing programming titles to a software engineer and baby toys to a new mother. There are three common approaches to solving the recommendation problem: traditional collaborative filtering, cluster models, and search-based methods. Here, we compare these methods with our algorithm, which we call item-to-item collaborative filtering. Unlike traditional collaborative filtering, our algorithm's online computation scales independently of the number of customers and number of items in the product catalog. Our algorithm produces recommendations in real-time, scales to massive data sets, and generates high quality recommendations.",Symptoms in Queries,Q1 journal,10.1109/MIC.2003.1167344,Yes
A26,Information systems,Justifying Recommendations Using Distantly-Labeled Reviews and Fine-Grained Aspects,"Several recent works have considered the problem of generating reviews (or 'tips') as a form of explanation as to why a recommendation might match a customer’s interests. While promising, we demonstrate that existing approaches struggle (in terms of both quality and content) to generate justifications that are relevant to users' decision-making process. We seek to introduce new datasets and methods to address the recommendation justification task. In terms of data, we first propose an 'extractive' approach to identify review segments which justify users' intentions; this approach is then used to distantly label massive review corpora and construct large-scale personalized recommendation justification datasets. In terms of generation, we are able to design two personalized generation models with this data: (1) a reference-based Seq2Seq model with aspect-planning which can generate justifications covering different aspects, and (2) an aspect-conditional masked language model which can generate diverse justifications based on templates extracted from justification histories. We conduct experiments on two real-world datasets which show that our model is capable of generating convincing and diverse justifications.",Amazon Review,Conference,10.18653/v1/D19-1018,Yes
A27,Movies,Session-based Recommendations with Recurrent Neural Networks,"We apply recurrent neural networks (RNN) on a new domain, namely recommender systems. Real-life recommender systems often face the problem of having to base recommendations only on short session-based data (e.g. a small sportsware website) instead of long user histories (as in the case of Netflix). In this situation the frequently praised matrix factorization approaches are not accurate. This problem is usually overcome in practice by resorting to item-to-item recommendations, i.e. recommending similar items. We argue that by modeling the whole session, more accurate recommendations can be provided. We therefore propose an RNN-based approach for session-based recommendations. Our approach also considers practical aspects of the task and introduces several modifications to classic RNNs such as a ranking loss function that make it more viable for this specific problem. Experimental results on two data-sets show marked improvements over widely used approaches.",MovieLens,Conference,arXiv preprint arXiv:1511.06939,Yes
A28,Sociology,Romantic Partner Recommender Based on Speed Dating Experiment,"Most dating recommenders are based on online dating sites that make use of virtual user profiles portrayed by the users themselves. While speed dating collects real-life face-to-face dating interactions among people, the data is rarely applied in dating recommender in any form. This report explores the research gap and presents a novel dating recommender which combines speed dating study with dating recommender system. Speed dating data suggests that user profile portrayed by themselves may not accurately reflect their likeability as a potential romantic partner. We introduce an approach of extracting objective evaluation based on the objective ratings given by the dating partners in the speed dating events to construct an objective profile library. Due to the low match rate in speed dating, there is a high class imbalance on the match label in the speed dating dataset. The project applies SMOTE oversampling to mitigate the class imbalance issue. A random forest regression-based reciprocal recommender is presented. Experiment results confirm the effectiveness of the proposed approach. The combination of the objective profile library, SMOTE oversampling, and a random forest regression-based reciprocal recommender achieves a match prediction accuracy of 92.19%, outperforming existing benchmark algorithms.",Speed dating experiment,Conference,https://github.com/Sapphirine/romantic-partner-recommender-based-on-speed-dating-experiment,Yes
A29,Demography,A Machine Learning Approach to Census Record Linking,"Thanks to the availability of new historical census sources and advances in record-linking technology, economic historians are becoming big data genealogists. Linking individuals over time and between databases has opened up new avenues for research into intergenerational mobility, the long-run effects of early life conditions, assimilation, discrimination, and the returns to education. To take advantage of these new research opportunities, scholars need to be able to accurately and efficiently match historical records and produce an unbiased dataset of links for analysis. I detail a standard and transparent census matching technique for constructing linked samples that can be replicated across a variety of cases. The procedure applies insights from machine learning classification and text comparison to record linkage of historical data. My method teaches an algorithm to replicate how a well-trained and consistent researcher would create a linked sample across sources. I begin by extracting a subset of possible matches for each record, and then use training data to tune a matching algorithm that attempts to minimize both false positives and false negatives, taking into account the inherent noise in historical records. To make the procedure precise, I trace its application to an example from my own work, linking children from the 1915 Iowa State Census to their adult selves in the 1940 Federal Census. In addition, I provide guidance on a number of practical questions, including how large the training data needs to be relative to the sample.",US Census Record,Conference,https://api.semanticscholar.org/CorpusID:39601793,Yes
A30,Law,Prediction Machine Learning Models on Propensity Convicts to Criminal Recidivism,"Increasing internal state security requires an understanding of the factors that influence the commission of repetitive crimes (recidivism) since the crime is not caused by public danger but by the criminal person. Against the background of informatization of the information activities of law enforcement agencies, there is no doubt about the expediency of using artificial intelligence algorithms and blockchain technology to predict and prevent crimes. The prediction machine-learning models for identifying significant factors (individual characteristics of convicts), which affect the propensity to commit criminal recidivism, were applied in this article. For predicting the probability of propensity for criminal recidivism of customers of Ukrainian penitentiary institutions, a Decision Tree model was built to suggest the probability of repeated criminal offenses by convicts. It was established that the number of convictions to the actual punishment and suspended convictions is the main factors that determine the propensity of customers of penitentiary institutions to commit criminal recidivism in the future. Decision Tree models for the classification of convicts prone or not prone to recidivism were built. They can be used to predict new cases for decision-making support in criminal justice. In our further research, the possibility of using the technology of distributed registers/blockchain in predictive criminology will be analyzed.",Recidivism of felons on probation,Q2 journal,https://doi.org/10.3390/info14030161,Yes
A31,Marketing,Internet Advertisements Prediction,"The internet is a resourceful virtual world where a variety of information is open to public access, which expedites knowledge explosion. While the openness of the internet facilitates knowledge learning, it also carries some information people do not need. For instance, advertisements on the internet are one of the side products that have increasingly become a concern in recent years. The identification of advertisements on internet pages develops its necessity in areas such as internet security, search engines, or even education. In this paper, as an attempt to differentiate advertisements, some approaches are examined to predict the advertisements on internet pages. As a matter of fact, some promising results are presented in this paper.",Internet Advertisements,Conference,https://doi.org/10.1007/978-3-662-43871-8_60,Yes
A32,NLP,Enhancing Stance Detection through Sequential Weighted Multi-Task Learning,"The exponential growth of user-generated content on social media platforms, online news outlets, and digital communication has necessitated the development of automated tools for analyzing opinions and attitudes expressed in text. Stance detection, a critical task in Natural Language Processing, aims to identify the underlying perspective or viewpoint of an individual or group toward a specific topic or target. This paper explores the challenges of stance detection, particularly in the context of social media, where brevity, informality, and limited contextual information prevail. While sentiment analysis focuses on explicit sentiment polarity, stance detection classifies the stance or viewpoint of a text toward a target, often of an abstract nature. Motivated by recent achievements in Multi-Task Learning (MTL), this paper addresses the identified gap in the field, advocating further exploration in developing a joint neural architecture that integrates different opinion dimensions. In response, this study introduces two MTL models, Parallel Multi-Task Learning (PMTL) and Sequential Multi-Task Learning (SMTL), which incorporate sentiment analysis and sarcasm detection tasks to enhance stance detection performance. We address the complexities of MTL implementation with Transformer-based architectures and present an accessible architecture for this purpose. This study also proposes and evaluates four task weighting techniques, providing empirical evidence for their effectiveness in MTL models. Through comprehensive evaluations on benchmark datasets in both English and Arabic, we demonstrate that our most proficient model, a multi-target sequential MTL model with hierarchical weighting (SMTL-HW), achieves state-of-the-art results. These contributions underscore the potential of MTL in enhancing stance detection and offer valuable insights into the interaction between sentiment, stance, and sarcasm in text analysis.",Mawaqif,Conference,doi.org/10.1007/s13278-023-01169-7,Yes
A33,Information systems,Searching News Articles Using an Event Knowledge Graph Leveraged by Wikidata,"News agencies produce thousands of multimedia stories describing events happening in the world that are either scheduled such as sports competitions, political summits and elections, or breaking events such as military conflicts, terrorist attacks, natural disasters, etc. When writing up those stories, journalists refer to contextual background and to compare with past similar events. However, searching for precise facts described in stories is hard. In this paper, we propose a general method that leverages the Wikidata knowledge base to produce semantic annotations of news articles. Next, we describe a semantic search engine that supports both keyword based search in news articles and structured data search providing filters for properties belonging to specific event schemas that are automatically inferred.",Wikidata,Conference,https://doi.org/10.1145/3308560.331676,Yes
A34,Computer networks,Deep Learning Approach for Intelligent Intrusion Detection System,"Machine learning techniques are being widely used to develop an intrusion detection system (IDS) for detecting and classifying cyberattacks at the network-level and the host-level in a timely and automatic manner. However, many challenges arise since malicious attacks are continually changing and are occurring in very large volumes requiring a scalable solution. There are different malware datasets available publicly for further research by the cyber security community. However, no existing study has shown the detailed analysis of the performance of various machine learning algorithms on various publicly available datasets. Due to the dynamic nature of malware with continuously changing attacking methods, the malware datasets available publicly are to be updated systematically and benchmarked. In this paper, a deep neural network (DNN), a type of deep learning model, is explored to develop a flexible and effective IDS to detect and classify unforeseen and unpredictable cyberattacks. The continuous change in network behavior and rapid evolution of attacks makes it necessary to evaluate various datasets which are generated over the years through static and dynamic approaches. This type of study facilitates to identify the best algorithm which can effectively work in detecting future cyberattacks. A comprehensive evaluation of experiments of DNNs and other classical machine learning classifiers are shown on various publicly available benchmark malware datasets. The optimal network parameters and network topologies for DNNs are chosen through the following hyperparameter selection methods with KDDCup 99 dataset. All the experiments of DNNs are run till 1,000 epochs with the learning rate varying in the range [0.01-0.5]. The DNN model which performed well on KDDCup 99 is applied on other datasets, such as NSL-KDD, UNSW-NB15, Kyoto, WSN-DS, and CICIDS 2017, to conduct the benchmark. Our DNN model learns the abstract and high-dimensional feature representation of the IDS data.",KDD Cup 99,Conference,10.1109/ACCESS.2019.2895334,Yes
A35,Marketing,Time Series Model for Sales Predictions in the Wholesale Industry,"The prediction process in sales is a basis for a successful ongoing planning process for any organization. Wholesale companies, being B2B oriented, have to plan their organisational environment carefully to optimize the costs and maximize revenue. As the sales process is intersected with logistics, having precise sales predictions optimizes both sales and logistics processes. In order to track the sales towards a customer, we propose a data mart built on the top of the data warehouse to be used with daily loads of outgoing invoices and uninvoiced shipments data. Predictions are based on ARIMA model, one of the most popular forecasting models for the time series. The data is aggregated on a weekly level, as it was proven to be the most useful in this process. For the prediction purposes, we are focusing only on the outgoing invoices. From the business perspective, each product is tracked with data about the sales market, customer, quantity, and the date. In the article, the process of data preparation will also be included as it is the crucial step for successful prediction.",wholesale,Q2 journal,10.23919/MIPRO48935.2020.9245255,Yes
A36,Signal processing,Vehicle classification in distributed sensor networks,"The task of classifying the types of moving vehicles in a distributed, wireless sensor network is investigated. Specifically, based on an extensive real world experiment, we have compiled a data set that consists of 820 MByte raw time series data, 70 MByte of preprocessed, extracted spectral feature vectors, and baseline classification results using the maximum likelihood classifier. The purpose of this paper is to detail the data collection procedure, the feature extraction and pre-processing steps, and baseline classifier development.",Vehicle,Conference,https://doi.org/10.1016/j.jpdc.2004.03.020,Yes
A37,Sports,Player Recommendation System for Fantasy Premier League using Machine Learning,"Before the rise of popularity of Fantasy Sports, people were restricted to the passive consumption of sports via television and print media. With the rise of this new age industry, people are more involved with their stakes on their selected players. This aims to enable an average interested person to make informed decisions on which players to choose and invest in based on visualizations, statistical measures, and analytics. In the past, parameters like Return of Investment (ROI) were used as a metric, but that alone is insufficient to make decisions. We attempt to solve the favoritism bias (people tend to choose from their favorite teams) and generate actionable insights using Statistical Analysis and Data Science. We use the data extracted from Fantasy Premier League (FPL) API and test against the English Premier League 2021-22 (Soccer).",Fantasy football,Conference,10.1109/JCSSE54890.2022.9836260,Yes
A38,Management information systems,Personality Prediction Through CV Analysis using Machine Learning Algorithms for Automated E-Recruitment Process,"Personality of a person plays a crucial role in the organizational progress and also in the self-development process in an individual's life. One of the typical ways to predict the person's personality is either by a standard review or by scrutinizing the Curriculum Vitae of the candidate. The Conventional method of recruiting the candidates involves manual short listing of job seekers resumes according to the requirement of the company. In this work, a system that automates the task of segregating candidates based on eligibility criteria and personality evaluation in a recruitment process is proposed. To meet this requirement an online application is developed for the registration of candidate's details and analysis of candidate's personalities through an online Multiple-Choice Question (MCQ) test containing personality quizzes. Then the system analyzes professional eligibility by comparing the uploaded Curriculum Vitae trained datasets. This system employs a machine learning algorithm namely 'Logistic Regression' which helps to choose fair decisions to recruit a suitable candidate. Thus, the final results of the personality quizzes will be sent to both candidates and the admin.",CVs from Singapore,Q2 journal,10.1109/ICCCT53315.2021.9711787,Yes
A39,Music,On Using Artificial Intelligence to Predict Music Playlist Success,"The emergence of digital music platforms has fundamentally transformed the way we engage with and organize music. As playlist creation has gained widespread popularity, there is an increasing desire among music aficionados and industry experts to comprehend the factors that drive playlist success. This paper presents a machine learning-based approach designed to predict the success of music playlists. By analyzing various musical characteristics of songs, our model achieves an impressive accuracy of 89.6% in predicting playlist success. Notably, it exhibits a remarkable 92.0% accuracy in forecasting the success of popular playlists, while also effectively identifying unpopular playlists with an accuracy of 89.4%. These findings provide invaluable insights into playlist creation, ultimately enhancing the overall music-listening experience. By harnessing the power of machine learning, our proposed approach unlocks new prospects for optimizing playlist design strategies and delivering personalized music recommendations. This has significant ramifications for music enthusiasts and industry professionals seeking to elevate playlist creation and enrich the music consumption experience.",Million playlist dataset,Conference,10.1109/CCNC51664.2024.10454829,Yes
A40,Social networks,Detecting Compromised Accounts on the Pokec Online Social Network,"Online social networks have billions of users worldwide, and this number continues to grow. Users typically develop trust relationships with the accounts of other users, but the large number of users and potential gains from abuses of these trust relationships have attracted the attention of cyber-criminals. It is essential to prevent accounts from being compromised by these criminals. In this paper, an anomaly model trained on previous login data of users is applied to detect compromised accounts. The login data comes from the Pokec online social network, the largest community in Slovakia, where people can meet others and talk to their friends. The anomaly model monitors sudden changes in the behavior of a user trying to log in to their account, indicating a possible attempt by someone else to compromise the account. The efficiency of the anomaly model is validated by computing measures such as sensitivity, specificity, and overall accuracy. The results are promising, with real potential to detect compromised accounts.",Pokec Social Network,Conference,10.1109/DT.2017.8024272,Yes
A41,Food,Nantonac Collaborative Filtering: Recommendation based on Order Responses,"A recommender system suggests the items expected to be preferred by the users. Recommender systems use collaborative filtering to recommend items by summarizing the preferences of people who have tendencies similar to the user preference. Traditionally, the degree of preference is represented by a scale, for example, one that ranges from one to five. This type of measuring technique is called the semantic differential (SD) method. Web adopted the ranking method, however, rather than the SD method, since the SD method is intrinsically not suited for representing individual preferences. In the ranking method, the preferences are represented by orders, which are sorted item sequences according to the users' preferences. We here propose some methods to recommend items based on these order responses, and carry out the comparison experiments of these methods.",Sushi,Conference,https://doi.org/10.1145/3394171.3414031,Yes
A42,Urban studies,Data-Driven Real-Time Strategic Placement of Mobile Vaccine Distribution Sites,"Deployment of vaccines across the US provides significant defense against serious illness and death from COVID-19. Over 70% of vaccine-eligible Americans are at least partially vaccinated, but there are pockets of the population that are under-vaccinated, such as in rural areas and some demographic groups (e.g. age, race, ethnicity). These pockets are extremely susceptible to the Delta variant, exacerbating the healthcare crisis and increasing the risk of new variants. In this paper, we describe a data-driven model that provides real-time support to Virginia public health officials by recommending mobile vaccination site placement in order to target under-vaccinated populations. Our strategy uses fine-grained mobility data, along with US Census and vaccination uptake data, to identify locations that are most likely to be visited by unvaccinated individuals. We further extend our model to choose locations that maximize vaccine uptake among hesitant groups. We show that the top recommended sites vary substantially across some demographics, demonstrating the value of developing customized recommendation models that integrate fine-grained, heterogeneous data sources. We also validate our recommendations by analyzing the success rates of deployed vaccine sites, and show that sites placed closer to our recommended areas administered higher numbers of doses. Our model is the first of its kind to consider evolving mobility patterns in real-time for suggesting placement strategies customized for different targeted demographic groups.",SafeGraph Research Release,Conference,https://doi.org/10.1609/aaai.v36i11.21529,Yes
A43,Social media,A Benchmark for Toxic Comment Classification on Civil Comments Dataset,"Toxic comment detection on social media has proven to be essential for content moderation. This paper compares a wide set of different models on a highly skewed multi-label hate speech dataset. We consider inference time and several metrics to measure performance and bias in our comparison. We show that all BERTs have similar performance regardless of the size, optimizations or language used to pre-train the models. RNNs are much faster at inference than any of the BERT. BiLSTM remains a good compromise between performance and inference time. RoBERTa with Focal Loss offers the best performance on biases and AUROC. However, DistilBERT combines both good AUROC and a low inference time. All models are affected by the bias of associating identities. BERT, RNN, and XLNet are less sensitive than the CNN and Compact Convolutional Transformers.",Civil Comments,,,No
A44,Social media,Automated Hate Speech Detection and the Problem of Offensive Language,"A key challenge for automatic hate-speech detection on social media is the separation of hate speech from other instances of offensive language. Lexical detection methods tend to have low precision because they classify all messages containing particular terms as hate speech and previous work using supervised learning has failed to distinguish between the two categories. We used a crowd-sourced hate speech lexicon to collect tweets containing hate speech keywords. We use crowd-sourcing to label a sample of these tweets into three categories: those containing hate speech, only offensive language, and those with neither. We train a multi-class classifier to distinguish between these different categories. Close analysis of the predictions and the errors shows when we can reliably separate hate speech from other offensive language and when this differentiation is more difficult. We find that racist and homophobic tweets are more likely to be classified as hate speech but that sexist tweets are generally classified as offensive. Tweets without explicit hate keywords are also more difficult to classify.",Twitter offensive language,,,No
A45,Health,Classifying Early Infant Feeding Status from Clinical Notes Using Natural Language Processing and Machine Learning,"The objective of this study is to develop and evaluate natural language processing (NLP) and machine learning models to predict infant feeding status from clinical notes in the Epic electronic health records system. The primary outcome was the classification of infant feeding status from clinical notes using Medical Subject Headings (MeSH) terms. Annotation of notes was completed using TeamTat to uniquely classify clinical notes according to infant feeding status. We trained 6 machine learning models to classify infant feeding status: logistic regression, random forest, XGBoost gradient descent, k-nearest neighbors, and support-vector classifier. Model comparison was evaluated based on overall accuracy, precision, recall, and F1 score. Our modeling corpus included an even number of clinical notes that was a balanced sample across each class. We manually reviewed 999 notes that represented 746 mother-infant dyads with a mean gestational age of 38.9 weeks and a mean maternal age of 26.6 years. The most frequent feeding status classification present for this study was exclusive breastfeeding [n = 183 (18.3%)], followed by exclusive formula bottle feeding [n = 146 (14.6%)], and exclusive feeding of expressed mother’s milk [n = 102 (10.2%)], with mixed feeding being the least frequent [n = 23 (2.3%)]. Our final analysis evaluated the classification of clinical notes as breast, formula/bottle, and missing. The machine learning models were trained on these three classes after performing balancing and down sampling. The XGBoost model outperformed all others by achieving an accuracy of 90.1%, a macro-averaged precision of 90.3%, a macro-averaged recall of 90.1%, and a macro-averaged F1 score of 90.1%. Our results demonstrate that natural language processing can be applied to clinical notes stored in the electronic health records to classify infant feeding status. Early identification of breastfeeding status using NLP on unstructured electronic health records data can be used to inform precision public health interventions focused on improving lactation support for postpartum patients.",Infant Health and Development Program (IHDP),,,No
A46,Demography,Combining Family History and Machine Learning to Link Historical Records: The Census Tree Data Set,"A key challenge for research on many questions in the social sciences is that it is difficult to link records in a way that allows investigators to observe people at different points in their life or across generations. In this paper, we contribute to recent efforts to create these links with a new approach that relies on millions of record links created by individual contributors to a large, public, wiki-style family tree. We use these “true” links both to inform the decisions one needs to make when using automated methods to link records and as a training data set for use in a supervised machine learning approach. We describe our procedure and illustrate its potential by linking individuals across the 100% samples of the US censuses from 1900, 1910, and 1920. When linking adjacent censuses, we obtain an overall match rate of 62-65 percent (for over 88.9 million matches), with a false positive rate that is around 6-7 percent and with links that are similar to the population along observable characteristics. Thus, our method allows us to link records with a combination of a high match rate, precision, and representativeness that is beyond the current frontier. Finally, we demonstrate the potential of the data by estimating the degree of intergenerational transmission of literacy between father-son and mother-daughter pairs.",US Census Record,,,No
A47,Movies,Combining Provenance with Trust in Social Networks for Semantic Web Content Filtering,"Social networks are a popular movement on the web. On the Semantic Web, it is simple to make trust annotations to social relationships. In this paper, we present a two-level approach to integrating trust, provenance, and annotations in Semantic Web systems. We describe an algorithm for inferring trust relationships using provenance information and trust annotations in Semantic Web-based social networks. Then, we present an application, FilmTrust, that combines the computed trust values with the provenance of other annotations to personalize the website. The FilmTrust system uses trust to compute personalized recommended movie ratings and to order reviews. We believe that the results obtained with FilmTrust illustrate the success that can be achieved using this method of combining trust and provenance on the Semantic Web.",FilmTrust,,,No
A48,Health,Comparison of Multivariate Linear Regression and a Machine Learning Algorithm Developed for Prediction of Precision Warfarin Dosing in a Korean Population,"Personalized warfarin dosing is influenced by various factors including genetic and non-genetic factors. Multiple linear regression (LR) is known as a conventional method to develop predictive models. Recently, machine learning approaches have been extensively implemented for warfarin dosing due to the hypothesis of non-linear association between covariates and stable warfarin dose. To extend the multiple linear regression algorithm for personalized warfarin dosing in a Korean population and compare with a machine learning-based algorithm. From this cohort study, we collected information on 650 patients taking warfarin who achieved steady state including demographic information, indications, comorbidities, comedications, habits, and genetic factors. The dataset was randomly split into training set (90%) and test set (10%). The LR and machine learning (gradient boosting machine [GBM]) models were developed on the training set and were evaluated on the test set. LR and GBM models were comparable in terms of accuracy of ideal dose (75.38% and 73.85%), correlation (0.77 and 0.73), mean absolute error (0.58 mg/day and 0.64 mg/day), and root mean square error (0.82 mg/day and 0.9 mg/day), respectively. VKORC1 genotype, CYP2C9 genotype, age, and weight were the highest contributors and could obtain 80% of maximum performance in both models. This study shows that our LR and GBM models are satisfactory to predict warfarin dose in our dataset. Both models showed similar performance and feature contribution characteristics. LR may be the appropriate model due to its simplicity and interpretability.",Warfarin,,,No
A49,Biology,Context and Prediction Matter for the Interpretation of Social Interactions Across Species,"Interpreting social interactions in animals is crucial for understanding their behavior and evolution. Contextual factors and predictive models play a significant role in accurately identifying and interpreting these interactions. This study explores how different contexts and predictive frameworks can influence the interpretation of social behaviors in various species. By incorporating machine learning algorithms and contextual data, we aim to enhance the accuracy and depth of understanding of animal social interactions. The findings could have implications for ethology, conservation efforts, and the development of AI models for behavior prediction.",Animal Behavior,,,No
A50,Health,COVID-19 Vaccination Intent and Willingness to Pay in Bangladesh: A Cross-Sectional Study,"This article reports the intent to receive a SARS-COV-2 vaccine, its predictors and willingness to pay in Bangladesh. We carried out an online cross-sectional survey of 697 adults from the general population of Bangladesh in January 2021. A structured questionnaire was used to assess vaccination intent. The questionnaire included sociodemographic variables and health belief model constructs which may predict vaccination intent. Among the participants, 26% demonstrated a definite intent, 43% probable intent, 24% probable negative, and 7% a definite negative intention. Multivariable logistic regression analyses suggest an association between definite intent and previous COVID-19 infection (OR: 2.86; 95% CI: 1.71-4.78), perceiving COVID-19 as serious (OR: 1.93; 1.04-3.59), the belief that vaccination would make them feel less worried about catching COVID-19 (OR: 4.42; 2.25-8.68), and concerns about vaccine affordability (OR: 1.51; 1.01-2.25). Individuals afraid of the side effects (OR: 0.34; 0.21-0.53) and those who would take the vaccine if the vaccine were taken by many others (OR: 0.44; 0.29-0.67) are less likely to have a definite intent. A definite negative intent is associated with the concern that the vaccine may not be halal (OR: 2.03; 1.04-3.96). Furthermore, 68.4% are willing to pay for the vaccine. The median amount that they are willing to pay is USD 7.08. The study findings reveal that the definite intent to receive the SARS-CoV-2 vaccination among the general population varies depending on their COVID-19-related health beliefs and no significant association was found with sociodemographic variables.",willingness-to-pay for vaccine,,,No
A51,Finance,Credit Elasticities in Less-Developed Economies: Implications for Microfinance,"Policymakers often prescribe that microfinance institutions increase interest rates to eliminate their reliance on subsidies. This strategy makes sense if the poor are rate insensitive: then microlenders increase profitability (or achieve sustainability) without reducing the poor's access to credit. We test the assumption of price inelastic demand using randomized trials conducted by a consumer lender in South Africa. The demand curves are downward sloping, and steeper for price increases relative to the lender's standard rates. We also find that loan size is far more responsive to changes in loan maturity than to changes in interest rates, which is consistent with binding liquidity constraints.",credit elasticities,,,No
A52,Finance,Credit Scoring in the Era of Big Data,"For most Americans, access to credit is an essential requirement for upward mobility and financial success. A favorable credit rating is necessary to purchase a home or car, to start a new business, to seek higher education, or to pursue other important goals. For many consumers, strong credit is also necessary to gain access to employment, rental housing, and essential services such as insurance. At present, however, individuals have very little control over how they are scored and have even less ability to contest inaccurate, biased, or unfair assessments of their credit. Traditional, automated credit-scoring tools raise longstanding concerns of accuracy and unfairness. The recent advent of new 'big-data' credit-scoring products heightens these concerns. The credit-scoring industry has experienced a recent explosion of start-ups that take an 'all data is credit data' approach, combining conventional credit information with thousands of data points mined from consumers' offline and online activities.",FICO,,,No
A53,Marketing,Data-driven text features for sponsored search click prediction,"Much search engine revenue comes from sponsored search ads displayed with algorithmic search results. To maximize revenue, it is essential to choose a good slate of ads for each query, requiring accurate prediction of whether or not users will click on an ad. Click prediction is relatively easy for the ads that have been displayed many times, and have significant click history, but in the long tail with minimal or no click history, other features are needed to predict user response. In this work, we investigate the use of novel text features for this problem, within the context of a state-of-the-art sponsored search system. In particular, we propose the use of detailed word-pair indicator features between the query and ad. We compare the new features to the traditional vector-space and language modeling features extracted in a typical information-retrieval style. We evaluate these approaches in a maximum-entropy ranking model using the click-view data from a commercial search-engine traffic. We show that the word-pair features are highly helpful for sponsored search click prediction, not only improving over the sophisticated click-history feedback based systems, but also compensating for the lack of click history to some extent. In contrast, we find that the language and vector-space modeling approaches are significantly less effective.",Commercial search-engine traffic,,,No
A54,Health,Decision support system for arrhythmia prediction using convolutional neural network structure without preprocessing,"Arrhythmia is a disease-influencing heart and is manifested by an irregular heartbeat. Atrial fibrillation (Afib), atrial flutter (Afl), and ventricular fibrillation (Vfib) are heart arrhythmias affecting predominantly senior citizens. An electrocardiogram (ECG) is a device serving to measure the ECG signal and diagnosis of an abnormal pattern which represents a heartbeat defects. Though it is possible to analyze these signals manually, in some cases it is a difficult task due to the often signal distortion by noise. Furthermore, manual analyzation of patterns is subjective and can lead to an inaccurate diagnosis. An automated computer-aided diagnosis (CAD) is a technique to eliminate these shortcomings. In this work, we present a 6-layer deep convolutional neural network (CNN) for automatic ECG pattern classification of the normal (Nr), Afib, Afl, and Vfib classes. This proposed CNN model requires simple feature extraction and no pre-processing of ECG signals. For two seconds ECG segments, the model obtained the accuracy of 97.78%, specificity and sensitivity of 98.82% and 99.76% respectively. This proposed system can be used as an assistant automatic tool in a clinical environment as a decision support system.",Arrhythmia,,,No
A55,Health,Deep Learning Approach to Text Analysis for Human Emotion Detection from Big Data,"Emotional recognition has emerged as an essential field of study that can expose various valuable insights. Emotions can be articulated in several ways, such as speech, facial expressions, written text, and gestures. Emotion recognition in text documents is fundamentally a content-based classification issue, including concepts from natural language processing (NLP) and deep learning. In this study, a deep learning-assisted semantic text analysis (DLSTA) has been proposed for human emotion detection using big data. Emotion detection from textual sources can be achieved utilizing NLP techniques, including word embeddings extensively used for tasks like machine translation, sentiment analysis, and question answering. NLP techniques improve learning-based methods' performance by incorporating the text's semantic and syntactic features. The numerical outcomes demonstrate that the proposed method achieves a human emotion detection rate of 97.22% and a classification accuracy rate of 98.02%, outperforming different state-of-the-art methods and can be further enhanced by other emotional word embeddings.",Health-related textual data,,,No
A56,Health,Deep Learning Classification of Cardiomegaly Using Combined Imaging and Non-imaging ICU Data,"In this paper, we investigate the classification of cardiomegaly using multimodal data, combining imaging data from chest radiography with routinely collected Intensive Care Unit (ICU) data comprising vital sign values, laboratory measurements, and admission metadata. In practice a clinician would assess for the presence of cardiomegaly using a synthesis of multiple sources of data, however, prior machine learning approaches to this task have focused on chest radiographs only. We show that non-imaging ICU data can be used for cardiomegaly classification and propose a novel multimodal network trained simultaneously on both chest radiographs and ICU data. We compare the predictive power of both single-mode approaches with the joint network. We use a subset of data from the publicly available MIMIC-CXR and MIMIC-IV datasets, which contain both chest radiographs and non-imaging ICU data for the same patients. The approach from non-imaging ICU data alone achieves an AUC of 0.684 and the standard chest radiography approach an AUC of 0.840. Our joint model achieves an AUC of 0.880. We conclude that non-imaging ICU data have predictive value for cardiomegaly, and that combining chest radiographs with non-imaging ICU data has the potential to improve model performance for the same subset of patients, with further work required to demonstrate a significant improvement.",MIMIC-CXR-JPG,,,No
A57,News,Distant Political News Classification: Facilitating Machine Learning Identification of News Topics Across Multilingual Text Corpora,"The increasing volume of online news has made it considerably more difficult for scholars to identify political news. Ongoing advances in computational methods and natural language processing help to tackle this challenge. Yet, scholars who aim to take a comparative approach to study political news content are facing the challenge of addressing multiple languages. Training individual supervised machine learning classifiers for multiple languages is a costly and time-consuming process. Instead of relying on labels generated by manual coding, we explore the use of `distant' labels created by cues in article URLs. Specifically, we explore how sections reflected in URLs (e.g., nytimes.com/politics/) can help create training material for supervised machine learning classifiers. Using cues provided by news media organizations, such an approach allows for efficient political news identification at scale, while also allowing easy implementation across languages. We rely on an existing data set that consists of approximately 870,000 URLs of news-related content from four different countries (Italy, Germany, Netherlands, Poland), with a large sample of hand-labelled articles for each country. We test this method by providing a comparison to 'classical' supervised machine learning and a multilingual BERT model. We also expand topic identification to sports, entertainment, and economic news. Our results suggest that the use of URL section cues to distantly annotate texts provides a cheap and easy-to-implement way of classifying large volumes of news texts that can save researchers much valuable resources without necessarily having to sacrifice quality.",New York Times Annotated Corpus,,,No
A58,Literature,Enhanced Emotion and Sentiment Recognition for Empathetic Dialogue System Using Big Data and Deep Learning Methods,"The article presents the results of work on improving sentiment and emotion recognition for Polish texts using a big data-based expansion process and larger neural language models. The proposed recognition method is intended to serve in a therapeutic dialogue system to analyze sentiment and emotion in human utterances. First, the language model is enhanced, by replacing the BERT neural language model with RoBERTa. Next, the emotion-based text corpus is enlarged. A novel process of augmenting an emotion-labeled text corpus using semantically similar data from an unlabeled corpus, inspired by semi-supervised learning methods, is proposed. The process of using the Common Crawl web archive to create an enlarged corpus, named CORTEX+pCC, is presented. An empathetic dialogue system named Terabot, incorporating the elaborated method, is also described. The system is designed to employ elements of cognitive-behavioral therapy for psychiatric patients. The improved language model trained on the enlarged CORTEX+pCC corpus resulted in remarkably improved sentiment and emotion recognition. The average accuracy and F1 scores increased by around 3% and 8% relative, which will allow the dialogue system to operate more appropriately for the emotional state of the patient.",Nominees corpus,,,No
A59,Health,Epileptic Seizures Prediction Using Deep Learning Techniques,"Epilepsy is a very common neurological disease that has affected more than 65 million people worldwide. In more than 30% of the cases, people affected by this disease cannot be cured with medicines or surgery. However, predicting a seizure before it actually occurs can help in its prevention through therapeutic intervention. Studies have observed that abnormal activity inside the brain begins a few minutes before the start of a seizure, which is known as the preictal state. Many researchers have tried to find a way for predicting this preictal state of a seizure but an effective prediction in terms of high sensitivity and specificity still remains a challenge. The current study proposes a seizure prediction system that employs deep learning methods. This method includes preprocessing of scalp EEG signals, automated features extraction using convolutional neural network, and classification with the support of vector machines. The proposed method has been applied on 24 subjects of scalp EEG dataset of CHBMIT resulting in successfully achieving an average sensitivity and specificity of 92.7% and 90.8% respectively.",Epileptic Seizures,,,No
A60,Marketing,Evaluation of Classification and Ensemble Algorithms for Bank Customer Marketing Response Prediction,"This article attempts to improve the performance of classification algorithms used in the bank customer marketing response prediction of an unnamed Portuguese bank using the Random Forest ensemble. A thorough exploratory data analysis (EDA) was conducted on the data in order to ascertain the presence of anomalies such as outliers and extreme values. The EDA revealed that the bank data had 45,211 instances and 17 features, with 11.7% positive responses. This was in addition to the detection of outliers and extreme values. Classification algorithms used for modeling the bank dataset include Logistic Regression, Decision Tree, Naïve Bayes, and the Random Forest ensemble. These algorithms were applied to both the balanced and original bank data using Orange 3.2 data mining application following the Cross Industry Standard for Data Mining (CRISP-DM), and the ten-fold cross-validation method. Results from the experimental methods revealed that the performance of the Random Forest ensemble improved when the data was balanced. Results also showed that the features duration, poutcome, contact, month, and housing were the most important features that contribute to the success of the bank customer marketing campaign for deposit subscription. The study also revealed that the duration of call to clients, response to past promotions, and the use of cell phone contribute positively to the success of the campaign. While the months of September, November, March, and April recorded higher subscription rates. Those in management cadre and technicians were found to have responded more positively to the campaign than those in other job categories.",Bank Marketing,,,No
A61,Economics,Food insecurity as a predictor of metabolic syndrome in U.S. female adults,"To examine the association between household food insecurity and metabolic syndrome in the U.S. female adult population. We analyzed the 2007–2014 U.S. National Health and Nutrition Examination Survey data. Sample included 4,249 female adults who had complete data on metabolic syndrome components, household food security, and important potential socio-demographic predictors of metabolic syndrome. Household food security was categorized as full, marginal, low, and very low. F-tests were used to compare those in full food security households and those in each of the other food security category households for prevalence and potential socio-demographic predictors of metabolic syndrome. Logistic regression analyses were used to determine the association between household food security and metabolic syndrome. Women in low food security households were significantly more likely to have a waist circumference ≥ 88 cm and to have fasting glucose >100 mg/dl. Women in very low food security households were significantly more likely to have high density lipoprotein <50 mg/dl. Women in low and very low food security households were significantly more likely to have triglycerides ≥ 150 mg/dl. Findings suggest that women in low and very low food security households are at increased risk for metabolic syndrome.",Adult,,,No
A62,Finance,Forecasting Loss Given Default for Peer-to-Peer Loans via Heterogeneous Stacking Ensemble Approach,"Peer-to-peer (P2P) lending is an emerging field in FinTech and is an alternative source of personal loans. However, P2P lending faces severe credit risk due to high information asymmetry and insufficient collateral. We develop a novel heterogeneous stacking ensemble (HSE) approach by using two real-world datasets to improve the loss given default (LGD) forecasting in the P2P lending domain. Some special data in P2P lending and macroeconomic variables are employed as supplementary data sources to further enhance the model performance. Our proposal is compared with several popular models, including parametric and non-parametric ones, in terms of predictive accuracy and capital requirement. Our finding reveals that special data in P2P lending (e.g., number of investors and loan description) and macroeconomic variables are powerful predictors of LGD in P2P lending. The proposed HSE model outperforms the benchmark models in most cases and significantly achieves optimal average ranks across all the evaluation metrics. The results remain robust under several validations.",Prosper loans network,,,No
A63,Health,Forecasting Patient Outcomes in Kidney Exchange,"Kidney exchanges allow patients with end-stage renal disease to find a lifesaving living donor by way of an organized market. However, not all patients are equally easy to match, nor are all donor organs of equal quality---some patients are matched within weeks, while others may wait for years with no match offers at all. We propose the first decision-support tool for kidney exchange that takes as input the biological features of a patient-donor pair, and returns (i) the probability of being matched prior to expiry, and (conditioned on a match outcome), (ii) the waiting time for and (iii) the organ quality of the matched transplant. This information may be used to inform medical and insurance decisions. We predict all quantities (i, ii, iii) exclusively from match records that are readily available in any kidney exchange using a quantile random forest approach. To evaluate our approach, we developed two state-of-the-art realistic simulators based on data from the United Network for Organ Sharing that sample from the training and test distribution for these learning tasks---in our application these distributions are distinct. We analyze distributional shift through a theoretical lens, and show that the two distributions converge as the kidney exchange nears steady-state. We then show that our approach produces clinically-promising estimates using simulated data. Finally, we show how our approach, in conjunction with tools from the model explainability literature, can be used to calibrate and detect bias in matching policies.",Kidney exchange program,,,No
A64,Management information systems,From Big Data to Deep Data to Support People Analytics for Employee Attrition Prediction,"In the era of data science and big data analytics, people analytics help organizations and their human resources (HR) managers to reduce attrition by changing the way of attracting and retaining talent. In this context, employee attrition presents a critical problem and a big risk for organizations as it affects not only their productivity but also their planning continuity. In this context, the salient contributions of this research are as follows. Firstly, we propose a people analytics approach to predict employee attrition that shifts from a big data to a deep data context by focusing on data quality instead of its quantity. In fact, this deep data-driven approach is based on a mixed method to construct a relevant employee attrition model in order to identify key employee features influencing his/her attrition. In this method, we started thinking 'big' by collecting most of the common features from the literature (an exploratory research) then we tried thinking 'deep' by filtering and selecting the most important features using survey and feature selection algorithms (a quantitative method). Secondly, this attrition prediction approach is based on machine, deep and ensemble learning models and is experimented on a large-sized and a medium-sized simulated human resources datasets and then a real small-sized dataset from a total of 450 responses. Our approach achieves higher accuracy (0.96, 0.98 and 0.99 respectively) for the three datasets when compared previous solutions. Finally, while rewards and payments are generally considered as the most important keys to retention, our findings indicate that 'business travel', which is less common in the literature, is the leading motivator for employees and must be considered within HR policies to retention.",IBM HR analytics,,,No
A65,Music,Generating Smooth Mood-Dynamic Playlists with Audio Features and KNN,"Users curate music playlists for many purposes, including focus, enjoyment and therapy. Popular music streaming services generate playlists automatically which are constant in genre or mood. We propose a method to automatically create playlists dynamic in both the Arousal-Valence emotion space and the audio features of songs. Our playlist algorithm uses a two-stage approach to sequentially choose songs, employing a K-Nearest Neighbors (KNN) model to gather potential songs based on emotion and analyzing them with acoustic similarity metrics. To evaluate the effectiveness of various audio feature data, KNN parameters, and similarity metrics, we developed a testing protocol which generates playlists that traverse both Arousal-Valence and audio feature spaces. We define evaluation metrics to measure a playlist's smoothness and evenness using the Pearson correlation coefficient between dimensions and the variance of steps between songs, respectively. Our algorithm successfully creates smooth and evenly-spaced playlists that transition cohesively in both mood and genre. We explore how the choice of audio feature data, similarity metric, and KNN parameters all have an effect on playlists' smoothness and evenness across these two spaces.",Million playlist dataset,,,No
A66,Finance,Home mortgage lending by applicant race: Do HMDA figures provide a distorted picture?,"The Home Mortgage Disclosure Act of 1975 (HMDA) was designed to further fair access to mortgage credit and requires lenders to report such information as location, loan amount, income, and race and sex for each application. However, race is missing in a significant proportion of applications taken by mail or phone. Given the widespread use of HMDA data by lenders, community groups, researchers, and regulators and the importance of mortgage lending as a public policy issue, the strengths and shortcomings of these data must be clearly understood. The main findings are that reported approval rates by race are significantly overstated for refinance and home improvement loans, while home purchase loans are little affected. A review of trends in how race is reported and in the technology of mortgage lending indicates that missing data on race will become a bigger and bigger problem in the near future.",HMDA,,,No
A67,Economics,"Household Income, Pandemic-Related Income Loss, and the Probability of Anxiety and Depression","We use data from the Household Pulse Survey that the US Census Bureau conducted from April 2020 to February 2021 to estimate the probability of symptoms of anxiety and depression among adult Americans. Lack of viable instruments prevent ruling out exogeneity, but the magnitude and strength of association between mental disease and, both, 2019 household income and pandemic-related employment income loss warrant serious attention. Our results stress the importance of policy support to the socially vulnerable in an economic emergency, including cash transfers such as those offered by the 2020 CARES Act or the 2021 America Rescue Plan.",Adult,,,No
A68,Computer vision,Human Emotion Detection Using DeepFace and Artificial Intelligence,"An emerging topic that has the potential to enhance user experience, reduce crime, and target advertising is human emotion recognition, utilizing DeepFace and Artificial Intelligence (AI). The same feeling may be expressed differently by many individuals. Accurately identifying emotions can be challenging, in light of this. It helps to understand an emotion's significance by looking at the context in which it is presented. Depending on the application, one must decide which AI technology to employ for detecting human emotions. Because of things like lighting and occlusion, using it in real-world situations can be difficult. Not every human emotion can be accurately detected by technology. Human-machine interaction technology is becoming more popular, and machines must comprehend human movements and expressions. When a machine recognizes human emotions, it gains a greater understanding of human behavior and increases the effectiveness of work. Text, audio, linguistic, and facial movements may all convey emotions. Facial expressions are important in determining a person's emotions. There has been little research undertaken on the topic of real-time emotion identification, utilizing face photos and emotions. Using an Artificial Intelligence-based DeepFace approach, the proposed method recognizes real-time feelings from facial images and live emotions of persons. The proposed module extracts the facial features from an active shape DeepFace model by identifying 26 facial points to recognize human emotions. This approach recognizes the emotions of frustration, dissatisfaction, happiness, neutrality, and wonder. The proposed technology is unique, in that it implements emotion identification in real-time, with an average accuracy of 94% acquired from actual human emotions.",FACES,,,No
A69,Health,Infant birth weight estimation and low birth weight classification in United Arab Emirates using machine learning algorithms,"Accurate prediction of a newborn's birth weight (BW) is a crucial determinant to evaluate the newborn's health and safety. Infants with low BW (LBW) are at a higher risk of serious short- and long-term health outcomes. Over the past decade, machine learning (ML) techniques have shown a successful breakthrough in the field of medical diagnostics. Various automated systems have been proposed that use maternal features for LBW prediction. However, each proposed system uses different maternal features for LBW classification and estimation. Therefore, this paper provides a detailed setup for BW estimation and LBW classification. Multiple subsets of features were combined to perform predictions with and without feature selection techniques. Furthermore, the synthetic minority oversampling technique was employed to oversample the minority class. The performance of 30 ML algorithms was evaluated for both infant BW estimation and LBW classification. Experiments were performed on a self-created dataset with 88 features. The dataset was obtained from 821 women from three hospitals in the United Arab Emirates. Different performance metrics, such as mean absolute error and mean absolute percent error, were used for BW estimation. Accuracy, precision, recall, F-scores, and confusion matrices were used for LBW classification. Extensive experiments performed using five-fold cross validation show that the best weight estimation was obtained using Random Forest algorithm with mean absolute error of 294.53 g while the best classification performance was obtained using Logistic Regression with SMOTE oversampling techniques that achieved accuracy, precision, recall and F1 score of 90.24%, 87.6%, 90.2% and 0.89, respectively. The results also suggest that features such as diabetes, hypertension, and gestational age, play a vital role in LBW classification.",Infant Health and Development Program (IHDP),,,No
A70,Health,Machine learning algorithm for early detection of end-stage renal disease,"End stage renal disease (ESRD) describes the most severe stage of chronic kidney disease (CKD), when patients need dialysis or renal transplant. There is often a delay in recognizing, diagnosing, and treating the various etiologies of CKD. The objective of the present study was to employ machine learning algorithms to develop a prediction model for progression to ESRD based on a large-scale multidimensional database. This study analyzed 10,000,000 medical insurance claims from 550,000 patient records using a commercial health insurance database. Inclusion criteria were patients over the age of 18 diagnosed with CKD Stages 1-4. We compiled 240 predictor candidates, divided into six feature groups: demographics, chronic conditions, diagnosis and procedure features, medication features, medical costs, and episode counts. We used a feature embedding method based on implementation of the Word2Vec algorithm to further capture temporal information for the three main components of the data: diagnosis, procedures, and medications. For the analysis, we used the gradient boosting tree algorithm (XGBoost implementation). The C-statistic for the model was 0.93 [(0.916-0.943) 95% confidence interval], with a sensitivity of 0.715 and specificity of 0.958. Positive Predictive Value (PPV) was 0.517, and Negative Predictive Value (NPV) was 0.981. For the top 1 percentile of patients identified by our model, the PPV was 1.0. In addition, for the top 5 percentile of patients identified by our model, the PPV was 0.71. All the results above were tested on the test data only, and the threshold used to obtain these results was 0.1. Notable features contributing to the model were chronic heart and ischemic heart disease as a comorbidity, patient age, and number of hypertensive crisis events. When a patient is approaching the threshold of ESRD risk, a warning message can be sent electronically to the physician, who will initiate a referral for a nephrology consultation to ensure an investigation to hasten the establishment of a diagnosis and initiate management and therapy when appropriate.",Renal failure,,,No
A71,Economics,Machine learning approach for multidimensional poverty estimation,"In the social sciences, a theoretical analysis has predominated in its research. The scarcity of data and its difficulty in collecting and storing it, has been the main limitation for the social sciences to adopt quantitative approaches. However, the large amount of information generated in recent years, mainly through the use of the Internet, has allowed the social sciences to include more and more quantitative analysis. This study proposes the use of technologies such as Machine Learning (ML) are the answers to solving this data scarcity. The objective is to estimate the multidimensional poverty index at the personal level in a particular territory of Ecuador by using Machine Learning (ML) regression models based on a limited amount of data for training. Ten ML models are compared, such as linear, regularized, and assembled models and Random Forest performs outstandingly against the other models. An error of 7.5% was obtained in the cross-validation and 7.48% with the test data set. The estimates are compared with statistical approximations of the MPI in a geographical area and it is obtained that the average MPI estimated by the model compared to the average reported by the statistical studies differs by 1%.",Poverty in Colombia,,,No
A72,Health,Machine learning based forecast for the prediction of inpatient bed demand,"Overcrowding is a serious problem that impacts the ability to provide optimal level of care in a timely manner. High patient volume is known to increase the boarding time at the emergency department (ED), as well as at post-anesthesia care unit (PACU). Furthermore, the same high volume increases inpatient bed transfer times, which causes delays in elective surgeries, increases the probability of near misses, patient safety incidents, and adverse events. The purpose of this study is to develop a Machine Learning (ML) based strategy to predict weekly forecasts of the inpatient bed demand in order to assist the resource planning for the ED and PACU, resulting in a more efficient utilization. The data utilized included all adult inpatient encounters at Geisinger Medical Center (GMC) for the last 5 years. The variables considered were class of inpatient encounter, observation, or surgical overnight recovery (SORU) at the time of their discharge. The ML based strategy is built using the K-means clustering method and the Support Vector Machine Regression technique (K-SVR). The performance obtained by the K-SVR strategy in the retrospective cohort amounts to a mean absolute percentage error (MAPE) that ranges between 0.49 and 4.10% based on the test period. Additionally, results present a reduced variability, which translates into more stable forecasting results. The results from this study demonstrate the capacity of ML techniques to forecast inpatient bed demand, particularly using K-SVR. It is expected that the implementation of this model in the workflow of bed capacity management will create efficiencies, which will translate in a more reliable, inexpensive and timely care for patients.",Adult,,,No
A73,Education,PaRe: A Paper-Reviewer Matching Approach Using a Common Topic Space,"Finding the right reviewers to assess the quality of conference submissions is a time consuming process for conference organizers. Given the importance of this step, various automated reviewer-paper matching solutions have been proposed to alleviate the burden. Prior approaches including bag-of-words model and probabilistic topic model are less effective to deal with the vocabulary mismatch and partial topic overlap between the submission and reviewer. Our approach, the common topic model, jointly models the topics common to the submission and the reviewer’s profile while relying on abstract topic vectors. Experiments and insightful evaluations on two datasets demonstrate that the proposed method achieves consistent improvements compared to the state-of-the-art.",,,,No
A74,Management information systems,Performance Predicting in Hiring Process and Performance Appraisals Using Machine Learning,"In the nowadays-competitive race of finding a suitable talented, qualified, bright and potential personnel to fulfill the needed spot of a vacancy in an industry, and with the beginning of the fourth industrial revolution, employers are taking the hiring process to the digital world. As Artificial Intelligent (AI) has a high-speed computation and adaptively to big data, it used to analyses and represents the data to employers in an easy way so they can make their decisions effectively. An upcoming challenge is raised where if the new candidates for a vacancy will give the expected performance based on the hiring criteria's or not, and how to hire a candidate that will while dealing with the hiring process? Employers are concerned with the performance evaluation of their current employees, but it is a challenge knowing the performance of new candidates before hiring. This study is proposing a follow-up conceptual model of using Artificial Intelligent (AI) in the hiring process with the using of performance management and social screening to predict the new candidate expected performance by analyzing historical performances and conditions of employees. This method will give an additional parameter that assists the decision makers in the hiring process. Although this method is a step forward to eliminate bad hiring, but it is requiring a huge historical data including the tracking of the performance, personal information collected from several sources like surveys and social Media and employees conditions related to the time of old and current employees, to give results that are more efficient and accurate.",Pymetrics bias group,,,No
A75,Health,Predicting Diabetes Mellitus With Machine Learning Techniques,"Diabetes mellitus is a chronic disease characterized by hyperglycemia. It may cause many complications. According to the growing morbidity in recent years, in 2040, the world's diabetic patients will reach 642 million, which means that one of the ten adults in the future is suffering from diabetes. There is no doubt that this alarming figure needs great attention. With the rapid development of machine learning, machine learning has been applied to many aspects of medical health. In this study, we used decision tree, random forest and neural network to predict diabetes mellitus. The dataset is the hospital physical examination data in Luzhou, China. It contains 14 attributes. In this study, five-fold cross validation was used to examine the models. In order to verify the universal applicability of the methods, we chose some methods that have the better performance to conduct independent test experiments. We randomly selected 68994 healthy people and diabetic patients' data, respectively as training set. Due to the data unbalance, we randomly extracted 5 times data. And the result is the average of these five experiments. In this study, we used principal component analysis (PCA) and minimum redundancy maximum relevance (mRMR) to reduce the dimensionality. The results showed that prediction with random forest could reach the highest accuracy (ACC = 0.8084) when all the attributes were used.",,,,No
A76,Health,Predicting sepsis with a recurrent neural network using the MIMIC III database,"Predicting sepsis onset with a recurrent neural network and performance comparison with InSight - a previously proposed algorithm for the prediction of sepsis onset. A retrospective analysis of adult patients admitted to the intensive care unit (from the MIMIC III database) who did not fall under the definition of sepsis at the time of admission. The area under the receiver operating characteristic (AUROC) measures the performance of the prediction task. We examine the sequence length given to the machine learning algorithms for different points in time before sepsis onset concerning the prediction performance. Additionally, the impact of sepsis onset's definition is investigated. We evaluate the model with a relatively large and thus more representative patient population compared to related works in the field. For a prediction 3 h prior to sepsis onset, our network achieves an AUROC of 0.81 (95% CI: 0.78–0.84). The InSight algorithm achieves an AUROC of 0.72 (95% CI: 0.69–0.75). For a fixed sensitivity of 90% our network reaches a specificity of 47.0% (95% CI: 43.1%–50.8%) compared to 31.1% (95% CI: 24.8%–37.5%) for InSight. In addition, we compare the performance for 6 and 12 h prediction time for both approaches. Our findings demonstrate that a recurrent neural network is superior to InSight considering the prediction performance. Most probably, the improvement results from the network's ability of revealing time dependencies. We show that the length of the look back has a significant impact on the performance of the classifier. We also demonstrate that for the correct detection of sepsis onset for a retrospective analysis, further research is necessary.",MIMIC III,,,No
A77,Education,Predicting Student Performance in Higher Educational Institutions Using Video Learning Analytics and Data Mining Techniques,"Technology and innovation empower higher educational institutions (HEI) to use different types of learning systems—video learning is one such system. Analyzing the footprints left behind from these online interactions is useful for understanding the effectiveness of this kind of learning. Video-based learning with flipped teaching can help improve student’s academic performance. This study was carried out with 772 examples of students registered in e-commerce and e-commerce technologies modules at an HEI. The study aimed to predict student’s overall performance at the end of the semester using video learning analytics and data mining techniques. Data from the student information system, learning management system, and mobile applications were analyzed using eight different classification algorithms. Furthermore, data transformation and preprocessing techniques were carried out to reduce the features. Moreover, genetic search and principle component analysis were carried out to further reduce the features. Additionally, the CN2 Rule Inducer and multivariate projection can be used to assist faculty in interpreting the rules to gain insights into student interactions. The results showed that Random Forest accurately predicted successful students at the end of the class with an accuracy of 88.3% with an equal width and information gain ratio.",HEI e-commerce modules,,,No
A78,Social work,Predicting Successful Placements for Youth in Child Welfare with Machine Learning,"Out-of-home placement decisions have extremely high stakes for the present and future well-being of children in care because some placement types, and multiple placements, are associated with poor outcomes. We propose that a clinical decision support system (CDSS) using existing data about children and their previous placement success could inform future placement decision-making for their peers. The objective of this study was to test the feasibility of developing machine learning models to predict the best level of care placement (i.e., the placement with the highest likelihood of doing well in treatment) based on each youth's behavioral health needs and characteristics. We developed machine learning models to predict the probability of each youth's treatment success in psychiatric residential care (i.e., Psychiatric Residential Treatment Facility [PRTF]) versus any other placement (AUROCs > 0.70) using data collected in standard care at a behavioral health organization. Placement recommendations based on these machine learning models distinguished between youth who did well in residential care versus non-residential care (e.g., 80% of those who received care in the recommended setting with the highest predicted likelihood of success had above-average risk-adjusted outcomes). Then we developed and validated machine learning models to predict the probability of each youth's treatment success across specific placement types in a state-wide system, achieving an average AUROC score of >0.75. Machine learning models based on risk-adjusted behavioral health and functional data show promise in predicting positive placement outcomes and informing future placement decisions for youth in care. Related ethical considerations are discussed.",Allegheny Child Welfare,,,No
A79,Social media,Preemptive Toxic Language Detection in Wikipedia Comments Using Thread-Level Context,"We address the task of automatically detecting toxic content in user-generated texts. We focus on exploring the potential for preemptive moderation, i.e., predicting whether a particular conversation thread will, in the future, incite a toxic comment. Moreover, we perform preliminary investigation of whether a model that jointly considers all comments in a conversation thread outperforms a model that considers only individual comments. Using an existing dataset of conversations among Wikipedia contributors as a starting point, we compile a new large-scale dataset for this task consisting of labeled comments and comments from their conversation threads.",Wikipedia Toxic Comments,,,No
A80,Health,Psychosocial Factors Predict the Level of Aggression of People with Drug Addiction: A Machine Learning Approach,"This study aimed to identify the relevant psychosocial factors that can predict the aggression in people with drug addiction. A total of 896 male participants (Mean age = 38.30 years) completed the survey. Gradient boosting regression, a machine learning algorithm, was used to find the relevant psychosocial variables, such as psychological security, psychological capital, interpersonal trust, and alexithymia, that may be significantly related to aggressive behavior. Results showed that the five most important factors in the prediction of aggression are interpersonal trust, psychological security, psychological capital, parental conflict, and alexithymia. A high level of interpersonal trust, psychological security, and psychological capital can predict a low level of aggression in people with drug addiction, while a high level of parental conflict and alexithymia can predict a high level of aggression. Overall, the findings highlight the need to focus interventions according to the relation between these psychosocial factors and aggression in order to decrease violence.",,,,No
A81,Education,Revolutionizing University Graduate Employability: Leveraging Advanced Machine Learning Models to Optimize Campus Recruitment and Placement Strategies,"In the competitive landscape of the job market, universities are faced with the challenge of not only providing quality education but also ensuring the successful placement of their graduates into the workforce. The use of advanced machine learning models offers a promising solution to this challenge by providing universities with the ability to efficiently analyze vast amounts of data and identify patterns that can be used to optimize their recruitment and placement strategies. In this paper, we delve into the exciting world of machine learning and explore how it can revolutionize university graduate employability. From predictive models that analyze student performance, interests, and career aspirations to identify the best-fit job opportunities for each student, to machine learning algorithms that match job candidates with suitable job openings based on their skills, experience, and qualifications, the possibilities are endless. It is essential for universities and companies to implement responsible machine learning practices and ensure that their algorithms are fair and unbiased to prevent issues of bias and discrimination. As the job market becomes more competitive and complex, universities and companies must leverage advanced technologies to remain competitive and attract top talent. By embracing machine learning and developing responsible machine learning practices, universities can optimize their recruitment and placement strategies and enhance the employability of their graduates. The use of advanced machine learning models presents an exciting opportunity for universities to optimize their recruitment and placement strategies and revolutionize university graduate employability.",Campus Recruitment,,,No
A82,Economics,Risk Prediction in Automobile Insurance,"The relationship between individual risks and the number of claims in automobile insurance has received growing attention over recent years among industry practitioners. The number of people who purchase cars grows exponentially. Risk managers of insurance companies need to deal with a variety of risks concerning vehicles and try to predict them as accurately as possible to avoid losses or minimize them. For this reason, in this thesis, I will examine different risk variables and models for these variables in the car insurance sector. The analyses are done based on the econometric approach. The main problem of the thesis concerns the risk prediction by count data models in automobile insurance. First, the analysis will be done by Poisson regression model using maximum likelihood estimator. Then the Gamma heterogeneity will be taken into account and the negative-binomial regression model will be discussed. The latter provides a framework for the bonus-malus scheme. The extensions of Poisson regression will also be considered in this thesis. The models will be applied to the real data and the estimation results will be discussed at the end of the thesis.",Italian car insurance,,,No
A83,Health,Short-Term and Long-Term Readmission Prediction in Uncontrolled Diabetic Patients using Machine Learning Techniques,"Diabetes is a chronic disease and major health problem which leads to many complications if not managed probably. Hyperglycemia, or raised blood sugar, is a common effect of Uncontrolled diabetes that may leads overtime to serious complications, especially in the nerves and blood vessels. As well as leads to repeated hospital admission. The main purpose of this study is to help clinicians to improve healthcare of uncontrolled diabetic patients through using machine learning as a tool in decision making, consequently this will improve patient care and reduce the readmission which considered a medical quality measurement and cost reduction objective. This study aims to predict the hospital readmission of the uncontrolled diabetic patient who is considered more susceptible to developing life-threatening diabetes complications and based on the Diabetes 130-US hospitals dataset. Several machine learning employed to predict the short term (within 30 days), and both short and long-term readmission (within or after 30 days) of uncontrolled diabetic patient. As expected, the results are in line with other research in the literature. For the first scenario of whole readmission prediction, our model achieved a better accuracy of 64.5 % with SVM and attribute selection and for the second scenario, RF achieved the highest accuracy of 86.38 % which still come in context with other research in the literature.",130-US hospitals,,,No
A84,Health,Skin Lesion Classification Based on Convolutional Neural Network,"Skin cancer is one of the most common cancers, and its early detection can have a huge impact on its outcomes. Deep learning, especially convolutional neural networks, perform well in processing massive amounts of data, especially image data in classifying skin cancer. In this paper, convolutional neural networks are mainly used to diagnose and classify 7 types of skin lesions, including melanoma, basal cell carcinoma, melanocytic nevus, actinic keratosis, and intraepithelial carcinoma, benign keratinoid lesions, dermatofibroma, and vascular lesions. First, the characteristics of skin lesion images are analyzed, using image processing technology and sampling technology to preprocess skin lesion images. Then the training parameters of imageNet network are adjusted through the idea of transfer learning on InceptionV3, ResNet50, DenseNet201, and other networks to perform training classification. Furthermore, different convolutional neural network models are built for classification. In order to validate the classification performance of various convolutional neural network models, this paper adopts ISIC 2017 HAM10000 dataset for experiments. The experimental results show that proper preprocessing is necessary when applying CNN for image classification. In classifying the 224*224 skin lesion images, the classical deep convolutional network with DenseNet201 achieved a remarkable performance classification accuracy of 99.12% for training and 86.91% for testing.",HAM10000,,,No
A85,Computer vision,Student Attendance with Face Recognition (LBPH or CNN): Systematic Literature Review,"Technology growth is speedy, and more and more things can be solved easily with the existence of sophisticated technology. One of them is solving the problem of student attendance at the university. The current attendance system has developed into RFID (Radio Frequency Identification) from the previous manual. However, many things still become obstacles. For example, students who miss their cards cannot take attendance, and the problem of leaving attendance can be cheating. Now, this has developed much technology in the form of face recognition with various algorithms that can be used. The use of face recognition can overcome the previous problem because it only uses faces for attendance. However, the many algorithms for facial recognition make it difficult to determine the best algorithm to implement. The main purpose of this literature review is to compare algorithms suitable for implementation in an environment at universities, especially CNN and LBPH. Based on the literature review, it was found that CNN's accuracy is superior in terms of accuracy compared to LBPH, CNN also produces more stable accuracy if there are external factors that can affect accuracy.",FairFace,,,No
A86,Social media,Studying Political Bias via Word Embeddings,"Machine Learning systems learn bias in addition to other patterns from input data on which they are trained. Bolukbasi et al. pioneered a method for quantifying gender bias learned from a corpus of text. Specifically, they compute a gender subspace into which words, represented as word vectors, can be placed and compared with one another. In this paper, we apply a similar methodology to a different type of bias, political bias. Unlike with gender bias, it is not obvious how to choose a set of definitional word pairs to compute a political bias subspace. We propose a methodology for doing so that could be used for modeling other types of bias as well. We collect and examine a 26 GB corpus of tweets from Republican and Democratic politicians in the United States (presidential candidates and members of Congress). With our definition of a political bias subspace, we observe several interesting and intuitive trends including that tweets from presidential candidates, both Republican and Democratic, show more political bias than tweets from other politicians of the same party. This work models political bias as a binary choice along one axis, as Bolukbasi et al. did for gender. However, most kinds of bias - political, racial and even gender bias itself - are much more complicated than two binary extremes along one axis. In this paper, we also discuss what might be required to model bias along multiple axes (e.g. liberal/conservative and authoritarian/libertarian for political bias) or as a range of points along a single axis (e.g. a gender spectrum).",Twitter Presidential Politics,,,No
A87,Social work,Substance Use and Sentiment and Topical Tendencies: A Study Using Social Media Conversations of Youth Experiencing Homelessness,"This study investigates associations between Facebook (FB) conversations and self-reports of substance use among youth experiencing homelessness (YEH). YEH engage in high rates of substance use and are often difficult to reach, for both research and interventions. Social media sites provide rich digital trace data for observing the social context of YEH's health behaviors. The authors aim to investigate the feasibility of using these big data and text mining techniques as a supplement to self-report surveys in detecting and understanding YEH attitudes and engagement in substance use. Participants took a self-report survey in addition to providing consent for researchers to download their Facebook feed data retrospectively. The authors collected survey responses from 92 participants and retrieved 33,204 textual Facebook conversations. The authors performed text mining analysis and statistical analysis including ANOVA and logistic regression to examine the relationship between YEH's Facebook conversations and their substance use. Facebook posts of YEH have a moderately positive sentiment. YEH substance users and non-users differed in their Facebook posts regarding: (1) overall sentiment and (2) topics discussed. Logistic regressions show that more positive sentiment in a respondent's FB conversation suggests a lower likelihood of marijuana usage. On the other hand, discussing money-related topics in the conversation increases YEH's likelihood of marijuana use.",Homeless Youths’ Social Networks,,,No
A88,Health,Supervised Machine Learning Models for Prediction of COVID-19 Infection using Epidemiology Dataset,"COVID-19 or 2019-nCoV is no longer pandemic but rather endemic, with more than 651,247 people around world having lost their lives after contracting the disease. Currently, there is no specific treatment or cure for COVID-19, and thus living with the disease and its symptoms is inevitable. This reality has placed a massive burden on limited healthcare systems worldwide especially in the developing nations. Although neither an effective, clinically proven antiviral agents' strategy nor an approved vaccine exist to eradicate the COVID-19 pandemic, there are alternatives that may reduce the huge burden on not only limited healthcare systems but also the economic sector; the most promising include harnessing non-clinical techniques such as machine learning, data mining, deep learning and other artificial intelligence. These alternatives would facilitate diagnosis and prognosis for 2019-nCoV pandemic patients. Supervised machine learning models for COVID-19 infection were developed in this work with learning algorithms which include logistic regression, decision tree, support vector machine, naive Bayes, and artificial neutral network using epidemiology labeled dataset for positive and negative COVID-19 cases of Mexico. The correlation coefficient analysis between various dependent and independent features was carried out to determine a strength relationship between each dependent feature and independent feature of the dataset prior to developing the models. The 80% of the training dataset were used for training the models while the remaining 20% were used for testing the models. The result of the performance evaluation of the models showed that decision tree model has the highest accuracy of 94.99% while the Support Vector Machine Model has the highest sensitivity of 93.34% and Naive Bayes Model has the highest specificity of 94.30%.",,,,No
A89,Education,"Supporting Decision-Making Process on Higher Education Dropout by Analyzing Academic, Socioeconomic, and Equity Factors through Machine Learning and Survival Analysis Methods in the Latin American Context","The prediction of university dropout is a complex problem, given the number and diversity of variables involved. Therefore, different strategies are applied to understand this educational phenomenon, although the most outstanding derive from the joint application of statistical approaches and computational techniques based on machine learning. Student Dropout Prediction (SDP) is a challenging problem that can be addressed following various strategies. On the one hand, machine learning approaches formulate it as a classification task whose objective is to compute the probability of belonging to a class based on a specific feature vector that will help us to predict who will drop out. Alternatively, survival analysis techniques are applied in a time-varying context to predict when abandonment will occur. This work considered analytical mechanisms for supporting the decision-making process on higher education dropout. We evaluated different computational methods from both approaches for predicting who and when the dropout occurs and sought those with the most consistent results. Moreover, our research employed a longitudinal dataset including demographic, socioeconomic, and academic information from six academic departments of a Latin American university over thirteen years. Finally, this study carried out an in-depth analysis, discusses how such variables influence estimating the level of risk of dropping out, and questions whether it occurs at the same magnitude or not according to the academic department, gender, socioeconomic group, and other variables.",Equitable School Access in Chicago,,,No
A90,Health,Textual emotion detection in health: Advances and applications,"Emotional recognition has arisen as an essential field of study that can expose a variety of valuable inputs. Emotion can be articulated in several means that can be seen, like speech and facial expressions, written text, and gestures. Emotion recognition in a text document is fundamentally a content-based classification issue, including notions from natural language processing (NLP) and deep learning fields. Hence, in this study, deep learning assisted semantic text analysis (DLSTA) has been proposed for human emotion detection using big data. Emotion detection from textual sources can be done utilizing notions of Natural Language Processing. Word embeddings are extensively utilized for several NLP tasks, like machine translation, sentiment analysis, and question answering. NLP techniques improve the performance of learning-based methods by incorporating the semantic and syntactic features of the text. The numerical outcomes demonstrate that the suggested method achieves an expressively superior quality of human emotion detection rate of 97.22% and the classification accuracy rate of 98.02% with different state-of-the-art methods and can be enhanced by other emotional word embeddings.",,,,No
A91,Economics,The Stealth Legitimization of a Controversial Policy Tool: Statistical Profiling in French Public Employment Service,"Statistical profiling algorithms claiming to predict which jobseekers are at risk of becoming long-term unemployed are spread unevenly across countries. However, the pathways and histories of these tools are understudied. Because the profiling path in France is a winding one, it is fruitful to study the production of profiling acceptability within the Public Employment Service (PES), and upstream of its reception by frontline advisers. Using a mix of interviews and written sources, we show that the production of profiling acceptability sits at the crossroads of two processes: technical and political transformations of the instrument itself and broader institutional and managerial transformations of the PES. On the basis of this case study, the paper enriches our understanding of the slow and incremental rationalization of public services that we have termed 'professional rationalization.' We argue that, far from being a softened or moderated form of bureaucratic rationalization, it is powerful—perhaps even irreversible—precisely because it transforms its target (frontline advisers) before the rationalization instrument is even deployed.",ANPE,,,No
A92,Finance,Understanding and Promoting Micro-Finance Activities in Kiva.org,"Non-profit Micro-finance organizations provide loaning opportunities to eradicate poverty by financially equipping impoverished, yet skilled entrepreneurs who are in desperate need of an institution that lends to those who have little. Kiva.org, a widely-used crowd-funded micro-financial service, provides researchers with an extensive amount of publicly available data containing a rich set of heterogeneous information regarding micro-financial transactions. Our objective in this paper is to identify the key factors that encourage people to make micro-financing donations, and ultimately, to keep them actively involved. In our contribution to further promote a healthy micro-finance ecosystem, we detail our personalized loan recommendation system which we formulate as a supervised learning problem where we try to predict how likely a given lender will fund a new loan. We construct the features for each data item by utilizing the available connectivity relationships in order to integrate all the available Kiva data sources. For those lenders with no such relationships, e.g., first-time lenders, we propose a novel method of feature construction by computing joint nonnegative matrix factorizations. Utilizing gradient boosting tree methods, a state-of-the-art prediction model, we are able to achieve up to 0.92 AUC (area under the curve) value, which shows the potential of our methods for practical deployment. Finally, we point out several interesting phenomena on lenders' social behaviors in micro-finance activities.",Kiva,,,No
A93,Transportation,"Understanding Ride-Hailing Sharing and Matching in Chicago Using Travel Time, Cost, and Choice Models","Ride-hailing data is sparingly available throughout the U.S., which limits researchers' understanding of the mode. Chicago is one of a few cities that have mandated ride-hailing companies to submit detailed trip data to their local transportation agency. The dataset is one of the few to contain trip-level attributes such as fare, travel time, and trip length. Most research using the Chicago dataset has focused on understanding why people use ride-hailing. This study focuses on why ride-hailing passengers choose shared over private trips and what influences the shared trips to be matched. Trips to/from airports are less likely to be shared. Trips to/from low-income areas are more likely to be shared. Longer shared trips are more likely to be matched, shared trips to/from dense areas are more likely to be matched, and shared trips between areas with a high number of shared trips are more likely to be matched. Matching an additional shared trip with another adds approximately 4 min to a trip. Ride-hailing users' value of time is found to be $48.23 per hour. Understanding travel behavior is important for all modes of transportation including ride-hailing. The results of this paper can be applied to guide policies aiming to promote more sustainable transportation modes.",Chicago Ridesharing,,,No
A94,Library and information sciences,Unsupervised Differentiable Multi-aspect Network Embedding,"Network embedding is an influential graph mining technique for representing nodes in a graph as distributed vectors. However, the majority of network embedding methods focus on learning a single vector representation for each node, which has been recently criticized for not being capable of modeling multiple aspects of a node. To capture the multiple aspects of each node, existing studies mainly rely on offline graph clustering performed prior to the actual embedding, which results in the cluster membership of each node (i.e., node aspect distribution) fixed throughout the training of the embedding model. We argue that this not only makes each node always have the same aspect distribution regardless of its dynamic context, but also hinders the end-to-end training of the model that eventually leads to the final embedding quality largely dependent on the clustering. In this paper, we propose a novel end-to-end framework for multi-aspect network embedding, called asp2vec, in which the aspects of each node are dynamically assigned based on its local context. More precisely, among multiple aspects, we dynamically assign a single aspect to each node based on its current context, and our aspect selection module is end-to-end differentiable via the Gumbel-Softmax trick. We also introduce the aspect regularization framework to capture the interactions among the multiple aspects in terms of relatedness and diversity. We further demonstrate that our proposed framework can be readily extended to heterogeneous networks. Extensive experiments towards various downstream tasks on various types of homogeneous networks and a heterogeneous network demonstrate the superiority of asp2vec.",4area,,,No
A95,Social work,Using a Machine Learning Tool to Support High-Stakes Decisions in Child Protection,"Machine learning decision support tools have become popular in a range of social domains including healthcare, criminal justice, and child welfare. But the design of these tools often fails to consider the potentially complex interactions that happen between the tools and humans. This lack of human-centered design is one reason that so few tools are actually deployed, and even if they are, struggle to achieve impact. In this article, we present the example of the Allegheny Family Screening Tool, a machine learning model used since 2016 to support hotline screening of child maltreatment referrals. We describe aspects of human-centered design that contributed to the successful deployment of this tool, including agency leadership and ownership, transparency by design, ethical oversight, community engagement, and social license. Finally, we identify potential next-steps to encourage greater integration of human-centered design into the development and implementation of machine learning decision support tools.",Allegheny Child Welfare,,,No
A96,Social work,Using Artificial Intelligence to Identify Emergency Messages on Social Media During a Natural Disaster: A Deep Learning Approach,"During natural disasters, emergency communication systems become overloaded, and people are forced to turn to social media to make requests for help. This study employs machine learning and artificial intelligence to automatically detect, identify, and categorize tweets relevant to first responders during Hurricane Harvey. We curate a dataset of tweets, present a labeling scheme based on relevance and urgency, and develop neural and non-neural machine learning models to automatically categorize tweets. Our best relevance classifiers, language models BERT and XLNet, perform significantly better than non-neural models and the deep convolutional neural network (CNN) and achieve comparable F1 scores. Ultimately, this study furthers machine learning and crisis communication research by developing methods to automatically categorize tweets that can signal to first responders of individuals' requests for help in urgent, life-threatening disasters. Our work also finds large pretrained language models promising for the development of well-performing disaster tweet classifiers in future work.",Harvey Rescue,,,No
A97,Economics,Using Machine Learning for Automated Assessment of Misclassification of Goods for Fraud Detection,"The paper is devoted to providing automated solutions to an actual problem of misclassification of goods in cross-border trade. In this paper, we introduce a hybrid approach to Harmonized System (HS) code assessment that combines the knowledge derived from textual descriptions of products, assigned to them HS codes and taxonomy of HS codes nomenclature. We use machine learning for providing HS code’s predictions and recommendations on the basis of a model learned from the textual descriptions of the products. In order to perform an assessment of misclassification of goods we present a novel combined similarity measure based on cosine similarity of texts and semantic similarity of HS codes based on HS code taxonomy (ontology). The method is evaluated on the real open source data set of Bill of Lading Summary 2017 using Gensim Python library.",US Harmonized tariff schedule,,,No
A98,Social work,"Using Machine Learning to Identify Predictors of Sexually Transmitted Infections Over Time Among Young People Living With or at Risk for HIV Who Participated in ATN Protocols 147, 148, and 149","Sexually transmitted infections (STIs) among youth aged 12 to 24 years have doubled in the last 13 years, accounting for 50% of STIs nationally. We need to identify predictors of STI among youth in urban HIV epicenters. Sexual and gender minority (gay, bisexual, transgender, gender-diverse) and other youth with multiple life stressors (homelessness, incarceration, substance use, mental health disorders) were recruited from 13 sites in Los Angeles and New Orleans (N = 1482). Self-reports and rapid diagnostic tests for STI, HIV, and drug use were conducted at 4-month intervals for up to 24 months. Machine learning was used to identify predictors of time until new STI (including a new HIV diagnosis). At recruitment, 23.9% of youth had a current or past STI. Over 24 months, 19.3% tested positive for a new STI. Heterosexual males had the lowest STI rate (12%); African American youth were 23% more likely to acquire an STI compared with peers of other ethnicities. Time to STI was best predicted by attending group sex venues or parties, moderate but not high dating app use, and past STI and HIV seropositive status. Sexually transmitted infections are concentrated among a subset of young people at highest risk. The best predictors of youth's risk are their sexual environments and networks. Machine learning will allow the next generation of research on predictive patterns of risk to be more robust.",Homeless Youths’ Social Networks,,,No
A99,Urban studies,Using Mobile Device Traces to Improve Near-Real Time Data Collection During the George Floyd Protests,"This research note presents a method for using mobile device trace data to improve collection of data on spontaneously erupting protest activity and related events. Based on this method, it presents a highly granular dataset of such activity for the George Floyd Protests in the United States. We use anonymous aggregated mobile device trace data to identify device surges—anomalous changes in the number of devices in a small geographic area—consistent with the assembly of a large number of individuals. Preliminary estimates from ongoing data collection of protest sites and scale are presented. Establishing better measures of where and when protests occur across and within cities improves researchers' understanding of the downstream political and social consequences of mobilization.",SafeGraph Research Release,,,No
A100,Literature,Who could be behind QAnon? Authorship attribution with supervised machine-learning,"A series of social media posts on 4chan then 8chan, signed under the pseudonym ‘Q’, started a movement known as QAnon, which led some of its most radical supporters to violent and illegal actions. To identify the person(s) behind Q, we evaluate the coincidence between the linguistic properties of the texts written by Q and to those written by a list of suspects provided by journalistic investigation. To identify the authors of these posts, serious challenges have to be addressed. The ‘Q drops’ are very short texts, written in a way that constitute a sort of literary genre in itself, with very peculiar features of style. These texts might have been written by different authors, whose other writings are often hard to find. After an online ethnography of the movement, necessary to collect enough material written by these thirteen potential authors, we use supervised machine learning to build stylistic profiles for each of them. We then performed a ‘rolling analysis’, looking repeatedly through a moving window for parts of Q’s writings matching our profiles. We conclude that two different individuals, Paul F. and Ron W., are the closest match to Q’s linguistic signature, and they could have successively written Q’s texts. These potential authors are not high-ranked personality from the US administration, but rather social media activists.",nominees corpus,,,No
A101,Social networks,You are who you know: inferring user profiles in online social networks,"Online social networks are now a popular way for users to connect, express themselves, and share content. Users in today's online social networks often post a profile, consisting of attributes like geographic location, interests, and schools attended. Such profile information is used on the sites as a basis for grouping users, for sharing content, and for suggesting users who may benefit from interaction. However, in practice, not all users provide these attributes. In this paper, we ask the question: given attributes for some fraction of the users in an online social network, can we infer the attributes of the remaining users? In other words, can the attributes of users, in combination with the social network graph, be used to predict the attributes of another user in the network? To answer this question, we gather fine-grained data from two social networks and try to infer user profile attributes. We find that users with common attributes are more likely to be friends and often form dense communities, and we propose a method of inferring user attributes that is inspired by previous approaches to detecting communities in social networks. Our results show that certain user attributes can be inferred with high accuracy when given information on as little as 20% of the users.",Rice Social Network,,,No